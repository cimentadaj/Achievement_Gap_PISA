% Things to remember:
% The working directory is not where the data is.
% Change working directory to "/Users/cimentadaj/Downloads/gitrepo/Achievement_Gap_PISA/paper"
% for everything below to work.

% There's a code chunk named modeling which lasts about 3-4 hours to run. I explain how to get
% around that in a comment above the code chunk. For down there.

\documentclass[11pt, a4paper]{article}
\bibliographystyle{apalike}
\pagestyle{headings}

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
\usepackage{pdflscape}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage[round, colon]{natbib}
\usepackage[colorlinks]{hyperref}
\usepackage{booktabs}
\AtBeginDocument{%
  \hypersetup{
    citecolor=blue,
    linkcolor=blue,   
    urlcolor=blue}}

\title{The not so widening achievement gap: an interntational comparison of the evolution of the SES achievement gap from 2000-2015}
\author{Jorge Cimentada}


\begin{document}
\setlength{\parindent}{2em}
\setlength{\parskip}{1em}
\showboxdepth=5
\showboxbreadth=5

\maketitle

<<working directory, echo = F>>=
options(scipen = 213141)

opts_chunk$set(echo = FALSE,
               message = FALSE,
               cache = TRUE,
               warning = FALSE,
               include = FALSE,
               cache.lazy = FALSE,
               results = 'asis')
@

<<default_conf>>=
  library(matrixStats)
  library(knitr)
  library(arm)
  library(saves)
  library(haven)
  library(PISA2000lite)
  library(PISA2003lite)
  library(PISA2006lite)
  library(PISA2009lite)
  library(PISA2012lite)
  library(intsvy)
  library(cimentadaj) # devtools::install_github("cimentadaj/cimentadaj")
  library(countrycode) # For region variable
  library(car)
  library(SAScii)
  library(inequalityintsvy) # devtools::install_github("cimentadaj/inequalityintsvy")
  library(lme4)
  library(modelr)
  library(ggrepel)
  library(xtable)
  library(ggthemes)
  library(tidyverse)

  
  # source("./transform_data.R")

  # Conf for PISA_2015
  pisa2015_conf <- list(variables = list(pvlabelpref = "PV",
                                         pvlabelsuff = "READ",
                                         weightFinal = "W_FSTUWT",
                                         weightBRR = "W_FSTURWT"),
          parameters = list(cutoffs = c(357.77, 420.07, 482.38, 544.68, 606.99, 669.30),
                                          percentiles = c(5, 10, 25, 75, 90, 95),
                                          PVreps = 10,
                                          BRRreps = 80,
                                          weights = "BRR",
                                          replication_scheme = 'pisa')
  )
  
  countries <- c("Finland",
                 "France",
                 # "New Zealand",
                 "Austria",
                 "Australia",
                 "Sweden",
                 # "Czech Republic",
                 "Canada",
                 "Hungary",
                 # "Iceland",
                 "Netherlands",
                 "Spain",
                 # "Belgium",
                 "Italy",
                 # "Norway",
                 "United Kingdom",
                 # "Greece",
                 "Denmark",
                 # "Israel",
                 "Poland",
                 "United States",
                 "Germany"
                 # "Turkey",
                 # "Russia"
                 )
@

\tableofcontents

% pisa_listcol.Rdata is a dataset produced by the source() expression from the above
% code chunk
<<loading_data-recoding>>=
pisa_all <- read_rds("./data/pisa_listcol.Rdata")
  
pisa_all2 <- pisa_all

years <- seq(2000, 2015, 3)
  
db <- paste0("pisa", years)
pisa_all2$value <- map2(pisa_all2$value, db, ~ { .x$wave <- .y; .x})
pisa_all2$value[[1]]$CNT <- pisa_all2$value[[1]]$COUNTRY
  
pisa_all2$value <- map(pisa_all2$value, ~ {
  
# 2000 to 2015
# The coding is from 0 to 6, where 0 is no schooling and 6 is
# BA or above.

# When turning 0:6 to numeric, it becomes 1:7 that's why
# I recode 8:9 to NA. This, however, didn't work for last two surveys
  
  .x$father_edu <- car::recode(as.numeric(.x$FISCED), "8:9 = NA")
  .x$mother_edu <- car::recode(as.numeric(.x$MISCED), "8:9 = NA")
  .x$high_edu_broad <- pmax(.x$father_edu, .x$mother_edu)
  .x$country <- pisa_countrynames[as.character(.x$CNT)]
  
  if (any(unique(.x$wave) %in% c("pisa2012", "pisa2015"))) {
    # These two surveys were from 0:6 so I had to add + 1
    # so that it equals 1:7 as all other surveys.
    .x$father_edu <- .x$father_edu + 1
    .x$mother_edu <- .x$mother_edu + 1
    .x$high_edu_broad <- .x$high_edu_broad + 1
  }
  .x
})
  
reliability_pisa <-
  c("2000" = 0.81,
    "2003" = 0.85,
    "2006" = 0.78,
    "2009" = 0.74,
    "2012" = 0.82,
    "2015" = 0.74) # 2015 imputed

@

<<escs_trend>>=
  # Rescaled trend ESCS data to merge.
  # This only has data for seq(2000, 2012, 3) because
  # PISA 2015 has the ESCS trend variable.
  dir <- tempdir()
  file_name <- "escs_trend.zip"
  download.file("http://vs-web-fs-1.oecd.org/pisa/trend_escs_SPSS.zip",
                destfile = file.path(dir, file_name))
  unzip(file.path(dir, file_name), exdir = dir)
  escs_trend <- map(file.path(dir, list.files(dir, pattern = ".sav")), haven::read_spss)
  file.remove(file.path(dir, list.files(dir)))
  
  escs_trend <-
    map(escs_trend, ~ {
    mutate(.x, cnt = pisa_countrynames[cnt]) %>%
    rename(country = cnt)
  })
@

<<merge_escs_pisa>>=
   # Next we'll merge the ESCS data with the PISA data. As explained above, the 6th data (PISA
  # 2015) doesn't need to be merged so I exclude it with this vector
  exclude <- -6
  
  # Loop in parallel to the PISA data, the ESCS data and the year vector (which is seq(2012, 2015, 3))
  pisa_all2$value[exclude] <-
    pmap(list(pisa_all2$value[exclude], escs_trend, years[exclude]), function(.x, .y, .z) {
    
    # The escs data needs to have the key variables the same class as the
    # same data.
    escs <-
      .y %>% mutate(schoolid = as.numeric(schoolid),
                    stidstd = as.numeric(stidstd))
    
    # .z is the corresponding year that will be created as a column
    # And perform the same transformation of the key variables as in the ESCS data
    data_trend <-
      .x %>%
        mutate(
          year = .z,
          schoolid = as.numeric(as.character(SCHOOLID)),
          stidstd = as.numeric(as.character(STIDSTD))
          ) %>%
   left_join(escs,
              by = c("country", "schoolid", "stidstd"))
    
    message(paste(unique(.x$wave), "done"))
    
    data_trend
  })
  
  pisa_all2$value[[6]] <-
    pisa_all2$value[[6]] %>%
    rename(escs_trend = ESCS)
@

<<functions_for_modelling>>=

# Function calculates the bottom 30th quantile for the bottom educated and the 70th quantile
# for the top educated. If the quantiles can't be estimated, it returns two NA's instead
quantile_missing <- function(df, weights, probs) {
    
    quan <- try(Hmisc::wtd.quantile(
      df$escs_trend,
      weights = df[[weights]],
      probs = probs
      ))

    if (any("try-error" %in% class(quan))) {
      return(c(NA, NA))
      } else {
     return(c(quan[1], quan[2]))
    }
}
  
# Producing the plot to get the difference between the top 30% of the high educated
# vs the bottom 30% of the low educated. This function loops through each dataset/country
# and survey reliability and estimates the difference while also extracting the s.e. of each
# difference.
  
# It returns a dataframe for each survey with all countries and respective coefficients and
# standard errors.
test_diff <- function(df, reliability, test, probs) {
  
    map2(df, reliability, function(.x, .y) {
      
      conf <- if (unique(.x$wave) == "pisa2015") pisa2015_conf else pisa_conf
      weights_var <- conf$variables$weightFinal

      country_split <- split(.x, .x$country)
      
      country_list <- map(country_split, function(country) {
        print(unique(country$country))
        
        quan <- quantile_missing(country, weights_var, probs)
        
        # It's very important to create a variable that returns the number of observations of this dummy
        # For each country. Possibly to weight by the number of observations.
        country$escs_dummy <-
          with(country, case_when(escs_trend >= quan[2] ~ 1,
                                  escs_trend <= quan[1] ~ 0))
        country
      })
      
      .x <-
        enframe(country_list) %>%
        unnest(value)

      .x <-
        .x %>%
        dplyr::select(wave,
                      matches(paste0("^PV.*", test, "$")),
                      escs_dummy,
                      country,
                      one_of(weights_var),
                      AGE)
      
      message(paste(unique(.x$wave), "data ready"))


      test_vars <- paste0("PV", seq_len(conf$parameters$PVreps), test)
      .x[test_vars] <- map(.x[test_vars], ~ ifelse(.x == 9997, NA, .x))
      
      # Calculate median math score of all PV's
      .x$dv <- rowMedians(as.matrix(.x[test_vars]), na.rm = T)
      
      # Should I estimate the model separately by country?
      mod1 <- lm(dv ~ AGE,
                 weights = .x[[weights_var]],
                 data = .x,
                 na.action = "na.exclude")
      
      # Take residuals of model and divide by rmse. Multiply that by
      # 1 / sqrt(reliability of each survey), which is .y in the loop.
      .x$adj_pvnum <- resid(mod1)/rmse(mod1, .x) * 1 / sqrt(.y)
      
      mod2 <-
        lmer(adj_pvnum ~ escs_dummy + (1 + escs_dummy | country),
             data = .x,
             weights = .x[[weights_var]])
      
      # Take the country coefficients (absolute coefficients)
      country_coef <-
        coef(mod2)$country %>%
        rownames_to_column() %>%
        gather(escs_dummy, Mean, -rowname) %>%
        mutate(escs_dummy = dplyr::recode(escs_dummy,
                                          `(Intercept)` = "0",
                                          `escs_dummy` = "1"))
      
      # Take the absolute country standard errors
      se <-
        se.coef(mod2)$country %>%
        as.data.frame() %>%
        rownames_to_column() %>%
        gather(escs_dummy, s.e., -rowname) %>%
        mutate(escs_dummy = dplyr::recode(escs_dummy,
                                          `(Intercept)` = "0",
                                          `escs_dummy` = "1"))
      
      results <-
        inner_join(country_coef, se, by = c("rowname", "escs_dummy")) %>%
        rename(country = rowname) %>%
        arrange(country, escs_dummy)
      
      message(paste0(unique(.x$wave), " modeling done"))
      results
    })
}


# Adapted from: https://github.com/jtleek/slipper/blob/master/R/slipper.R
# Returns a tibble with the actual expr + the bootstrapped expr.
bootstrapper <- function(df, expr, B = 100, n = nrow(df), replacement = TRUE) {
  bootstrapper_(df, lazyeval::lazy(expr), B, n, replacement)
}

bootstrapper_ <- function(df, expr, B = 500, n = nrow(df), replacement = TRUE) {
  obs_val = lazyeval::lazy_eval(expr, data = df)
  boot_val = replicate(B, {
    newdata = sample_n(df, n, replace = replacement)
    lazyeval::lazy_eval(expr, data = newdata)
  })
  out = tibble(type = c("observed", "bootstrap"), 
               value = c(obs_val, mean(boot_val, na.rm = T)))
  return(out)
}

# For example
# bootstrapper(mtcars, mean(mpg), B = 200)
@

% This chunk takes about 3-4 hours to run. Once I had them ready I saved them so you can read them
% as rds. If you run the 'compile pdf' this chunk is already cached (DONT CHANGE ANYTHING FROM
% THIS CHUNK, CAUSE OTHERWISE IT WILL RERUN FOR 3-4 HOURS). If you want to run the code without
% compiling sweave, comment the test_diff expressions and read as rds. 

% Remember to uncomment when compiling sweave again, so the chunk remains intact.
<<modeling>>=
adapted_year_data <-
    map(pisa_all2$value, ~ {
      if (unique(.x$wave) == "pisa2000") {
        # pisa2000 has a different coding so here I recode 6 to 7 so that in all waves the top edu
        # is 7 and the bottom is 1
        .x <-
          mutate(.x, new_hisced = as.character(dplyr::recode(as.numeric(high_edu_broad), `6` = 7)))
      } else {
        .x <-
          mutate(.x, new_hisced = as.character(high_edu_broad))
      }
      .x
})

results_math <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.1, 0.9))
results_read <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.1, 0.9))
results_math_topmid <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.5, 0.9))
results_read_topmid <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.5, 0.9))
results_math_midbottom <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.1, 0.5))
results_read_midbottom <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.1, 0.5))

# results_math <- read_rds("./data/delete.Rdata")
# results_read <- read_rds("./data/delete_read.Rdata")
# results_math_topmid <- read_rds("./data/delete_math_topmid.Rdata")
# results_read_topmid <- read_rds("./data/delete_read_topmid.Rdata")
# results_math_midbottom <- read_rds("./data/delete_math_midbottom.Rdata")
# results_read_midbottom <- read_rds("./data/delete_read_midbottom.Rdata")
# US is missing for reading

# Cache is not working properly for the code above, so I just load the saved cached file
# load("./paper/cache/modeling_9a0b38d1d53fa243b0242580f0672fa5.RData")
@

\section{Introduction}

\section{Literature Review}
% You have a bunch of citations to take from here
Educational inequality and its long term impacts is a topic that has been prominent in the social science literature for the past 30 years. The idea of meritocracy and intergenerational transfers have motivated, in conservative terms, much of the research on social mobility and social inequalities, for a good part of the 20th century and 21st century. When James Coleman released his famous Coleman report \citep{coleman1966}, it raised the topic to starlight by suggesting that family SES and student performance are tightly linked. The topic has been studied extensively since the report was released and several authors have contested whether the relationship is an invariable social law or a product of institutional arrangements. For a detailed review of the long literature on educational inequality, please see \citet{gamoran2001}. But fast-forward until today, we've understood the relationship much better.

Developmental psychology has been studying the subject for a long time and they find that the early stages in a child's life course are extremely important, if not the most, for cognitive and personality definition \citep{duyme1999, waldfogel1996}. Economists and educators have long neglected this branch of literature but the work of James Heckman has brought our attention to it. For example, he has clearly showed that cognitive and non-cognitive inequalities are present before entering school \citep{heckman2006}. This means that inequality starts strong before the schooling of a child begins and schools have the potential to equalize the learning ground. These inequalities can be narrowed significantly with high quality learning environments, specially for children coming from unfavourable conditions. But one of the most important findings from \citet{cunha2006} is that the cognitive level of a child in time \(t\) is a direct function of the experiencies from time \(t-1\). Although this sounds logical, it's importance is not understood entirely.

The implications of this cumulative model suggests that it is much less cost-effective to invest in children in time \(t\) that in \(t-1\). That is why the whole debate about narrowing inequality between high and low SES families should start in early education -- it is the cheaper than investing in later education and it brings about the largest returns. Despite all of these findings and investments to reduce the gaps, we still find that the relationship between parental education or socio-economic status is present in virtually all empirical studies of social mobility and inequalities \citep{breen1997, breen2007, waldfogel2006, bradbury2015, chetty2016}. What we don't know is how and why this relationship is formed from such an early age. Moreover, many have suggested different explanations and the topic has been very contested \citep{brooks1997}.

It is incomplete to study educational inequalities without considering the prevalence of intergenerational transmission of human and social capital. Social mobility has deepend our knowledge on the relationship between intergenerational transmission of SES and inequality of opportunity. The field of economics of education has also helped to understand that education is by far the investment that yields the best returns. This is not only for the child and his/her family, but to society as a whole, as it boosts economic activity, it helps the labour market to improve job conditions and maintain a rapid economic growth \citep{hanushek2007}. Since \citet{coleman1966} we've spent most of our time studying the mechanisms through which this inequality comes about. Naturally, we want to do that in order to reverse it and help every child reach its fullest potential. Despite our good intentions, we've concentrated little on the magnitud of the gaps, specially in terms of cognitive abilities. We still don't know, in comparative terms, which countries have big or small cognitive gaps resulting from SES origins. And even more importantly, we haven't assesed whether policy efforts to reduce inequality have actually had an impact in reducing the achievement gap over time.

Virtually in all countries, be it developed or developing, there is inequality of opportunity. But there is considerable variation in the magnitud of this effect. For example, the Scandinavian countries, particularly Denmark and Sweden, prove to be very mobile countries \citep{esping2012, breen2007, shavit1993}.

From Denmark, for example, the literature has learned a great deal about how to improve social mobility. But that was possible by first learning that Denmark is by far one of the most mobile countries, boosting the chances of upward mobility specially for less advantaged children \citep{bjorklund2009, jaeger2007}. The important finding came when we discovered the main reason behind their social escalator: it's educational system. For example, research by \citet{esping_waldfogel2012} and \citet{bauchmuller2014}, show that the Danish early education system has important and longstanding impacts in helping children reach their fullest potential. It does so very strongly for children which otherwise would be doomed to have a bleak future. Moreover, it tracks students into different curricula very late compared to other Europen countries (age 16), something which has been linked to less educational inequality. These two traits make the Danish system uniquely effective. The early schooling experience attempts to level children to the same degree and this process is not stopped by different curricular tracks because it starts at around age 16 when cognitive abilities are less malleable. In short, the importance of this finding, is that we should step back and first study whether the effect is there, how big is it, and then proceed to find the causes behind it.

The first attempt to study the evolution of the achievement gap has found that the gap in cognitive abilities between High-SES and Low-SES kids has been widening over the years. The literature on the topic has mainly concentrated on studying the American case \citep{reardon2011} but other international evidence is emerging with a very similar landscape. The United States is usually the case of study because it is the only country where cognitive testing is present as early as 1940. This time-trend has allowed researchers to study achievement gaps in a lengthy period of time. Using this information, \citet{reardon2011} is the first to investigate the evolution of the cognitive gap and the results are very surprising. Not only has the cognitive gap between the 90th income percentile and the 10th income percentile grown over time, but it has grown faster and to be wider than the highly contested white-black gap \citep{magnuson2008}. The gaps have actually reversed and now a days we find that the income achievement gap is nearly twice as large as the black-white achievement gap (quite the opposite to 20 years back).
% widening over the years? Gosta, page 3
% income achievement gap, gosta page 3

\citet{reardon2011} finds that the increase in the gaps has occured predominantely from the 1970's until the 2000's. In fact, the hard numbers suggest that the gap widened by 40-50\%. The author also estimates the rate of change using data as early as 1940 and finds an even higher increase of   75\%. Given that the studies before 1970 are less reliable in terms of comparability and sampling design, the author computes all results for both before/after 1970. To provide a definitive answer to the size of the gap, \citet{reardon2011} concludes that the U.S gap between the 90th and 10th income percentile is at about 1.25 standard deviations in the year 2001. Using longitudinal data, \citet{bradbury2015} find similar results. Their empirical analysis suggests that for American 14 year olds, the gap is above 1 standard deviation but lower than 1.25. Surprisingly, \citet{duncan2011} find similarly to the previous studies and confirm a gap of  1.25-1.50 standard deviations. One important drawback of these studies is that they don't present the uncertainty of this estimates. Not necessarily to gauge their statistical significance, but to simply asses how much we can trust their accuracy. It could be that the gap is at  1.25 standard deviations, varying up to 1.75 and down to 0.80. Right now we don't know the upper/lower bound of this estimate, making it difficult to compare when new evidence arises.

The first attempt to study the evolution of the achievement gap has found that the gap in cognitive abilities between High-SES and Low-SES kids has been widening over the years. The literature on the topic has mainly concentrated on studying the American case \citep{reardon2011} but other international evidence \citep{anna2016_global} is emerging with a very similar landscape. The United States is usually the case of study because it is the only country where cognitive testing is present as early as 1940. This time-trend has allowed researchers to study achievement gaps in a lengthy period of time. Using this information, \citet{reardon2011} is the first to investigate the evolution of the cognitive gap and the results are very surprising. Not only has the cognitive gap between the 90th income percentile and the 10th income percentile grown over time, but it has grown faster and to be wider than the highly contested white-black gap \citep{magnuson2008}. The gaps have actually reversed and now a days we find that the income achievement gap is nearly twice as large as the black-white achievement gap (quite the opposite to 20 years back).

Interestingly, this widening of the achievement gap has been paralleled by a growth of income inequality, a very suggestive explanation. \citet{reardon2011} offers several possible links, with the most reasonable being that family investment patterns have changed so that high income families now invest more resources on their children. This explanation lies in the fact that increasing income became more strongly correlated with other positive family traits related to time allocation and welfare services.

However likely, this is a highly contested topic. A recent \href{http://www.epi.org/files/pdf/101972.pdf}{report} by the Economic Policy Institute finds that the black-white income gap has been growing since 1979, very similar to the increase of income inequality. However, if the achiement gap would be a function of income inequality, we should expect for the white-black achievement gap to be widening rather than narrowing, and those are not the findings given by \citet{reardon2011} and \citet{magnuson2008} \footnote{The black-white achievement gap narrowed significantly for cohorts betwen 1950 and 1970 where income inequality was increasing.}.
.

In a follow-up study, \citet{reardon_portilla} unexpectedly uncovered a new finding: the reversal of the trend. This follow-up study concentrated solely on the kindergarten children in which they took a snapshot of the achievement gap in for 1998, 2006 and 2010. They found that the 90th/10th income gap in readiness closed modestly. Furthermore, using data from fall and spring in the same kindergarden year, they calculated that the gap narrowed at a rate of 0.01 and 0.008 standard deviations per year for mathematics and literacy between 1998 and 2010. They also calculated the same changes for a number of personality traits such as self-control and externalizing behaviour and found similar results. In contrast to \citet{reardon2011}, he finds that in a 30-year span the gap was systematicaly increasing at a rate of 0.02, something reasonably close to the previous estimates. Their results not only hold for the income achievement gap, but they also found a decline in the white-hispanic gap (although not for the white-black gap). It should be noted that perhaps the reversal of trend in \citet{reardon2011} would be obvious if data were available for years after 2000,  which is specifically the time that \citet{reardon_portilla} find the reversal.

The reasons the authors find a reversal in the trend could be numerous and should be studied very closely. The authors incorporate a number of country-level indicators to try and explaind this change and suggest that the reversal is likely due to the high increase of preschool enrollment. They suggest similarly that in this same period (1998 - 2010) the income achievement gap in early schooling enrollment decreased substantially. Their conclusions are very speculative and have no empirical support, which is why this is still an open question.
The reasons the authors find a reversal in the trend could be numerous and should be studied very closely. The authors incorporate a number of country-level indicators to try explain this change and suggest that the reversal is likely due to the high increase of preschool enrollment. In fact, the point out that in this same period (1998 - 2010) the SES gap in preschool enrollment decreased substantially. Their conclusions are very speculative and have no empirical support, which is why this is still an open question.


Motivated by these recent results, other authors have taken this analysis to an international context in order to discover between-country trends. The work of \citet{bradbury2015} employs a unique comparative analysis of the achievement gap between Australia, United Kingdom, United States and Canada. Their research design is very distinctive in that they use longitudinal data from children as early as age 2 and study the evolution of the achievement gap up until age 14 \footnote{To the best of my knowledge this is not only the first study that uses panel data to study achievement gaps, but to also do it between countries}. The core finding behind their study is that the American achievement gap is much wider than in any other comparison country, specially Australia and Canada. They find that once the achievement gap is present in early school entry, it doesn't seem to narrow or widen very much over the life course. In fact, they calculate that the quality of early education can only explain about  30-40\% of the high school SES gap. This suggests that once the achievement gap is present before entering school, it carries a social-scar effect \footnote{However, schooling could be preventing the gap to widen even more, and very rigorous RCT's show that high quality schooling can indeed help ease the gap, in some instances even close it \citep{campbell2002}.}. One exception is the United Kingdom, which they found to be a country that helps close the gap in early primary years. This can likely be due to the comprehensive schooling and also the public support by the welfare state in dimensions like health and income support.

One limitation of their study is that they concentrate on countries which have a very particular educational structure, namely the fact that there is little formal stratification in terms of curricula. These four countries have no major jump in school selection, quite the opposite to the average European country. A thorough review by \citet{werfhorst_mijs} sheds some light on the subject. First and foremost, they gather substantive evidence showing that countries which have a highly tracked curriculum tend to have high levels of inequality, measured in terms of achievement gaps. \citet{hanushek_woesmann_tracking}, use the Progress in International Reading Literacy Study (PIRLS), the Trends in International Mathematics and Science Study (TIMSS) and the Programme for International Student Assessment (PISA) surveys to gauge whether highly tracked countries do indeed increase inequality after students pass the age at first selection of tracking. The results suggest that early tracking increases educational inequality. While less clear, there is also a tendency for early tracking to reduce mean performance. \citet{micklewright} using PISA but a different empirical strategy, find that countries which have a high level of tracking, are distinctively unequal in the difference between the top 95th and bottom 5th performers. In fact, the difference in test scores between these two groups is about 10 times higher then the average annual gain of a year of schooling.

Another limitation of their study is that their analysis is based on four surveys that have significant differences in terms of questions, sampling and populations and cannot be easily compared. They do an amazing work at making the four surveys comparable and their findings are indeed very reliable.  But we should be careful at intepreting these findings causally and should be taken as suggestive at best. For this reason we should also pay particular attention to studies such as \citet{anna2016} and \citet{anna2016_global} which have attempted not only to compare gaps between countries, but to evaluate whether there is a general increase in the gap using much more comparable surveys. However it should be noted that these studies tackle a completely different question from the above, namely to study cross-sectional differences between many countries, instead of over-time analysis of student gaps. Nonetheless, they do provide support for the overall finding that the achievement gap is certainly not narrowing over time.

\citet{anna2016}, again using PIRLS, TIMSS and PISA, assess whether there are patterns of cross-national variation in the achievement gap. In other words, does the achievement gap differ between countries? Their work suggests that there is considerable variation in the achievement gap between top and bottom earning families across many developed countries. In comparison to the literature on achievement gaps, they find that the U.S has a gap of   1.20 SD in 2001 which increase to around ~ 1.30 in the year 2006 while Germany has a decreasing gap from around   1.25 to   1 standard deviation in the same year-span. However, these numbers vary a lot and carry a great deal of overlapping uncertainty.

They go even further and link this achievement gap to several country-level indicators related to income inequality, school differentiation and central exams, among other things. The correlations are very suggestive  as explanatory mechanisms but they are very cautious in drawing causality, specially because they are all reasonably correlated among each other.

One interesting question that is still missing from the literature is whether these country gaps have evolved over time. With their data, they only have 3 countries which are present in all waves but they also have very few waves because their question of interest (income categories) was only asked in three time points. That is why their study is more about between country gaps rather than the magnitude and evolution of the gaps.

\citet{anna2016_global}, building on the work of \citet{anna2016} and \citet{reardon_portilla} pooled together all the previously mentioned data, together with over 10 more studies ranging from the year 1964 until 2015 in order to discover differences between and across countries. With over 50 years of data, and over 100 countries, she finds that there seems to be a general pattern of increasing achievement gap. However, once she disentangles the relationship by country, she finds a sizable amount of heterogeneity, with some countries seeing the achievement gap narrowing, others no change at all, while others record a steady increase. This is revealing because it doesn't really pay off to look at a general average once each country has their own distinctive gap and evolution. Another important finding is that the achievement gap is clearly no universal and should be studied in context. 

One clear limitation of their study (as well as \citet{reardon2011}) is that they adjust for the age of each child in all studies. Although for their modeling purposes this is the correct thing to do \footnote{The differences in achievement could simply be due to changes in cognitive abilities across the lifetime. However, as we've noted before, \citet{bradbury2015} find that the achievement gap is very stable across the life time}, these modeling strategies are masking age-specific achievement gaps by controlling for age. We clearly see in \citet{reardon_portilla} that there are age-specific gaps, and they do change at a fast pace in very little time.

In fact, the evolution of high/low SES gaps for preschool children might be much less marked than the same gap for high school children. The explanation, although very debated, has been gaining much support in recent years. If we remember correctly, countries with high levels of curricular differentiation, the transition from early schooling into the tracking system has been found to increase inequality of learning \citep{hanushek_woesmann_tracking}. Moreover, the vast sociological literature on educational transitions systematically finds that tracking tends to foster between-track inequality rather than erode their differences by tackling their specific needs \citep{werfhorst_mijs}. Based on this, we cannot simply assume that the achievement gap has been neither constant across cohorts (because there have been tracking reforms in many countries, introducing as well as eliminating tracking structures) nor the same between ages, because tracking/no tracking might exarcebate the achievement gap.

% TODO: Talk about how the achievement gap has been widening in Malaysia and South Korea (or Japan?)
% Is efficiency related to opportunity here? Is efficiency what explains the inequality of opportunity?
% Note how many of these studies haven't really concentrated on who is getting better or worse: top or bottom?
% Talk more about how countries with high social mobility has been linked to smallest achievement gaps
% Talk about Durpiez and Dumay and how there's not relationship between inequality income - inequality achievement in contrast to reardon and anna who find some relationship.

\section{Research questions}

This study seeks to evaluate the evolution of the high/low SES achievement gap in the past 15 years for all PISA participant countries. This is different from previous work because it concentrates solely on 15 year old children, something not done for the achievement gap, and it attempts to capture the evolution of the achievement gap for countries with different educational systems. In addition, extend the previous findings by studying the relationship between the gap and the average performance of each country in order to detect if there's a tradeoff between good performance and equality over time separately for each country. The advantages of this study are twofold.

First, we concentrate on the evolution of the gap for only 15 year olds, which will serve as a comparison to the single year-country snapshot of \citet{anna2016} and the evolution of the kindergarten gap in \citet{reardon_portilla}. As we've seen before, there are reasons to think that specific age-groups have seen changes in the achievement gap. Moreover, in almost all countries with a tracked curriculum children are either at or in the process of tracking by the age 15, meaning that we will be able to link whether tracked countries are the most variable in their evolution of achievement gaps.

Second, we will be able, for the first time, to study the evolution of the achievement gap for several countries other than the United States. This will help asses the mangitude of the inequality as well as the rate of growth/decline. This study not only documents the size and changes of the SES gap, but pays particular attention to the source of the changes. That is, we study whether bottom performers are falling behind, if top performers are gaining advantages, or if both phenomenas are simultaneously at play.

More formally, we're interested in studying
a) Which countries are experiencing changes in the achievement gap;
b) the rate at which each country-gap is widening/narrowing and;
c) establishing whether the gaps are widening/narrowing because particular groups are getting ahead/behind.
d) The size of the achievement in a comparative perspective and its relationship to overall achievement levels;

We develop each question separately for more detail.

a) The seminal work of \citet{reardon2011} suggests that achievement gaps change, and they do so much quicker that we though. After recording a SES gap increase of about 40\% in only 30 years, \citep{reardon_portilla} stress that they also found a significant decrease in only 15 years of data. This shows that it is important to study the changes in the achievement gap over time. This will bring a useful comparison and pinpoint which countries are doing the best to reduce the gap.
a) The seminal work of \citet{reardon2011} suggests that achievement gaps change, and they do so much quicker that we though. After recording a SES gap increase of about 40\% in only 30 years, \citet{reardon_portilla} stress that they also found a significant decrease in only 15 years of data. This shows that it is important to study the changes in the achievement gap over time. This will bring a useful comparison and pinpoint which countries are doing the best to reduce the gap.

b) We want to compare the percentage change at which the gap widened/narrowed from the first to the last year available. This will give us a general idea of the overall change over time, and will allow us to compare our estimates to the actual literature \footnote{Although no study has performed this age-specific achievement gap for comparable tests over such a long time. Our results will serve as comparison for other studies that use age-specific groups, such as 4th graders using PIRLS.}

c) The widening/narrowing of the achievement gap has a source, which has been often studied to be related to everything from educational spending, income inequality, time allocation to students and preschool enrollment. The literature has concentrated very narrowly on whether the gap is increasing because the top performers are getting ahead, because both are distancing or because the bottom is falling behind. We shall pay particular attention to identifying the rate at which the top/bottom groups are evolving over time. This type of analysis is particularly useful in jotting down the mechanisms through which the gap is evolving. If the bottom performers are stagnated whereas the top is gaining ground, the performance-equality trade off dilemma of tracking might be much more credible than other explanations.

d) We want to test the notion that better performing countries have a smaller degree of inequality than other countries. \citet{werfhorst_mijs} emphasize that there is empirical evidence that suggests this. This pattern is not so obvious, however. For example, countries with high leves of tracking could maximize student performance, specially the high SES students, raising their overall performance and thus raising the national performance score. But if the bottom performers are not gaining at the same rate, then the achievement gap will inevitable grow resulting in a high performing countries with a widening achievement gap.

\section{Methods}

\subsection{Data}

<<country_sample_numeric_vec>>=
country_rows <- 
  map_dbl(adapted_year_data, nrow) %>%
  format(big.mark = ",")
@

To investigate the above mentioned questions I will be using the Programme for International Student Assessment (PISA). PISA is a survey carried out every three years that aims to evaluate education systems by testing the skills and knowledge of 15-year-old students. Currrently, PISA has six waves starting in 2000 up until 2015, where recently, over half a million students were tested in mathematics, literacy and science in over 70 developed/developing countries.

PISA collects data through a two-stage stratified sampling design. With the help of official governments, PISA randomly chooses 150 schools in each country, where they then randomly pick thirty 15 year olds to undertake the two hour tests. The sample size for PISA 2000 is \Sexpr{country_rows[1]}, \Sexpr{country_rows[2]} for PISA 2003, \Sexpr{country_rows[3]} for PISA 2006, \Sexpr{country_rows[4]} for PISA 2009, \Sexpr{country_rows[5]} for PISA 2012, and \Sexpr{country_rows[6]} for PISA 2015. Together with the subject tests, PISA collects personal information from students, their families and their school environment (including teacher surveys), that serves as relevent background information that can be matched to the students performance. With the recent inclusion of PISA 2015, these six waves make up a time-series analysis of 15 years, enough to visualize changes in the structure of an educational system. None of the literature cited so far has used the last PISA wave, which was recently released in December 2016.

To identify a family's socio-economic status PISA collects several variables that measure different dimensions. Classically, they ask student's their parent's educational level. Scholars have considered this to be a reliable recall given that we expect fifteen year olds to know their parent's level of education \citep{reardon2011}. This question has been asked in every wave and holds a somewhat similar coding across time, although the first two waves have small differences. In spite of this, another limitation is the fact that parent's education is measured using the ISCED classification, something that has changed over time. For example, until PISA 2009, the preferred framework was ISCED 1997, whereas the next wave switched to the newly developed ISCED 2011 classification. Both these classification schemes have equivalent look-up tables, but this requires a detailed inspection of the codings.

Another social background variable is the International Socio-Economic Index of Occupational Status (ISEI). This variable attempts to capture the social status of the family, without asking for income information. This index variable was developed by \citet{ganzeboom1996, ganzeboom2010} and it attempts to measure occupational status using a continuous measure. This indicator is a very reliable alternative to the  classical Erikson-Goldthorpe-Portocarero classification \citet{erikson1979}. It has been scaled for comparability between waves and some authors have used it for inequality studies, finding expected results to be consistent with the social mobility literature \citep{anna2016_global}. PISA also includes a plethora of indicators on family wealth, home educational resources, the number of books in the home, among many other material resources in the household.

Yet one of the most relevant variables for our study is a composite SES index created by the PISA team. The index of economic, social and cultural status (ESCS) was created on the basis of the following variables: the International Socio-Economic Index of Occupational Status (ISEI), the highest level of education of the student’s parents, the PISA index of family wealth (which measured the material wealth of the family), the PISA index of home educational resources; and the PISA index of possessions related to "classical" culture in the family home (mainly about books in the household) \citep{oecd_glance_2002}. This variable, aside from capturing all relevant dimensions of SES, such as education, occupation, and material resources, takes care of transforming all mentioned variables into comparable metrics across waves. 

The ESCS was derived from a principal component analysis of standardised variables, taking the factor scores for the first principal component as measures of the PISA index of economic, social and cultural status. All countries and economies (both OECD and partner countries/economies) contributed equally to the principal component analysis, while in previous cycles, the principal component analysis was based on OECD countries only. However, for the purpose of reporting the ESCS scale has been transformed with zero being the score of an average OECD student and one being the standard deviation across equally weighted OECD countries \citep{pisa_2015_results}.

To the best of our knowledge, this is the first paper that uses the newly-released ESCS index \citep{pisa_2015_results} which was rescaled so that all ESCS indexes are suitable for over-time analysis \footnote{These rescaled indices can be found in the \href{http://www.oecd.org/pisa/data/2015database/}{PISA website} under \emph{Rescaled Indices for Trend Analyses}.} In other words, the ESCS index does not need any transformation or coding updates because it is ready for comparison over time.

Aside from SES, the other most relevant variables are test scores for Mathematics and Literacy. PISA does not provide a single test result for each respondent. Instead, it provides a \emph{series} of 'plausible values' that the child could actually score. As explained in the PISA manual \citep{pisa2012_technical}, these are imputed values that resemble individual test scores and have approximately the same distribution as the latent trait being measured (the true distribution of the possible scores a student can achieve). 

A more intuitivity is explanation is this: suppose we have \(\mu_i\), the average student test score in Mathematics for student \(i\). Instead of estimating \(\mu_i\) alone, plausible values estimate a distribution of possible \(\mu\text{'s}\) for student \(i\), together with the likelihood of each \(\mu_i\) based on the respondents answers on the test. This is defined as the posterior distributions of \(\mu\text{'s}\) for student \(i\). The reason why we use this procedure is because estimating a single estimate \(\mu_i\) is plagued with measurement error, among other types of bias \citep[see][]{wu2005}. The number of plausible values for PISA waves are usually five (although ten for PISA 2015) random draws from this distribution. In practice each student has 5 scores for each test, that resemble their distribution. Those values are continuous, ranging from 0 to 500, with a mean of 250.

\subsection{Data analysis}

The aim of this paper is to identify and disaggregate country trends in the achievement gap for several countries. To represent the SES gap, most of the literature on achievement gaps has concentrated on indicators such as parental education, parental occupational status, income achievement gaps and actual SES achievement gaps \citep{fryer2004, hanushek_woesmann_tracking, saw2016, bradbury2015, byun2010}. The actual calculation of the achievement gap varies substantially and different strategies have been implemented. For example, \citet{micklewright} calculates the difference in achievement by crudely subtracting the gap between the 95th and 5th percentile of the mathematics distribution. Although in principle you should be able to capture some type of SES effect like this, theoretically, it should be much more accurate to difference out the mean score of, for example, parental education or some other SES proxy. \citet{saw2016}, for instance, used parental education as a proxy of SES, whereas \citet{byun2010} use a similar SES index as ours, but created by them.

\citet{reardon_portilla}, \citet{anna2016} and \citet{anna2016_global} used a different method developed by \citet{reardon2011} which we partially adopt in this paper. SES achievement gaps are measured as the difference in standardized achievement between the 90th and 10th percentiles of the chosen SES variable. The rule of thumb to choose the 90th, 50th and 10th percentile is arbitrary, as others have used, for example, the 5th, 50th and 95th \citep{micklewright}. We use the conventional 90/10 cutoffs in the literature following the standard set by \citet{reardon2011}.

For each country in each wave, SES disparities in achievement are measured as the gap in standardized achievement between the 90th and 10th percentiles of each country’s distribution of each SES variable, following Reardon’s (2011) method for income achievement gaps. The original strategy of \citet{reardon2011} is as follows: first, achievement is standardized (see below for a mathematical explanation of the standardization). We then use it to calculate the mean achievement (and standard error) for each category of the SES variable of interest (parent's education, income categories, etc..). "Category means are plotted at their percentile ranks and cubic models are fit through the points using weighted least squares. Finally, achievement at each country’s 90th and 10th SES percentiles is interpolated from the model" \citep{anna2016_global}. The result is a SES gap from an ordinal variable of interest.

As mentioned before, PISA does not provide a single achievement indicator. Instead, we take the median of all plausible values for each student \footnote{Since each plausible value is a random draw from a theoretical latent normal distribution of possible student achievement scores, the median should be precise in getting a central measure of the latent distribution.}, resulting in one single score.

To standardize the test score we fit a linear model

% Justify why you use the AGE variable
\begin{equation}
Y_i = \alpha + \beta_1 * AGE_i + \epsilon_i, \quad \epsilon_i ~ N(0, \sigma^2)
\end{equation}

for each wave, where \begin{math}Y_i\end{math} is the median student test score and \begin{math}AGE_i\end{math} is their age measured in months (following the same strategy as \citet{reardon2011}) weighted by the student sample weights.

We then adjust \begin{math} \hat{\gamma_i} \end{math} by

% I think the denominator could be wrong! Because I include y_hat and that's what the equation is estimating
\begin{equation}
\hat{\gamma_i} = \frac{\hat{\epsilon_i}}{\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2}}
\end{equation}

% # Take residuals of model and divide by rmse. Multiply that by
% # 1 / sqrt(reliability of each survey), which is .y in the loop.
% .x$adj_pvnum <- resid(mod1)/rmse(mod1, .x) * 1 / sqrt(.y)

Where \begin{math}\hat{\epsilon_i}\end{math} is the residual for student \begin{math}i\end{math} and the denominator is the root mean square error of the model.

This new standardized variable has a mean of zero. Standardizing the median test score solves the problem of comparability of gaps measured with different tests, and across waves because the test scores have now the same metric across time. However, if the variance of academic achievement changes over time, then standardizing the overall score at each country-wave pair actually makes the transformation biased. That is, by standardizing we're forcing the standard deviation of test scores to be zero across all waves. But if the true deviations of the median academic achievement changes over time, then the estimated trend in the SES gaps will be underestimated, or vice versa.

% Try plotting this for each country and wave
% Like, every country as a row and 6 columns for each wave.
\begin{figure}
\begin{center}
<<variance_pisa, include = T, out.height = '3in', out.width = '3.5in', fig.align = 'center'>>=

var_years <-
  map(adapted_year_data, function(.x) {
  .x %>%
  transmute(avg_cogn = matrixStats::rowMedians(as.matrix(select(.x, matches("^PV*.MATH$"))))) %>%
  summarize(var = sd(avg_cogn, na.rm = T),
            var_of_var = ) %>%
  pull(var)
})

enframer <- function(df, col_name = "name") {
  df %>%
    enframe(name = col_name) %>%
    unnest()
}

var_years %>%
  setNames(seq(2000, 2015, 3)) %>%
  enframer("name") %>%
  ggplot(aes(name, value)) +
  geom_col() +
  scale_y_continuous(name = "Standard deviation of raw test scores") +
  scale_x_discrete(name = NULL) +
  ggtitle("Standard deviation of test scores over time") +
  theme_few() +
  theme(text = element_text(size = 14))
@
\caption{Standard deviation of test scores across all waves.}
\end{center}
\end{figure}

We plot the standard deviation of the mathematics test score for all waves in figure 1. The plot suggests that it's something we shouldn't be deeply concerned with. The standard deviation of each wave seems to be following a very similar pattern with a not so drastic exception of the year 2000.

Another concern is that if the gaps at different waves are measured with tests that have different amounts of measurement error, then the amount of bias will not be the same in each measure of the gap. This can be very misleading and suggest erroneous intepretations regarding trends in the of the gaps over time \citep{reardon2011}. PISA has tried to make sure the tests are comparable across waves \citep{pisa2012_technical}, but we still have to adjust for this imprecision.

In order to correct gap estimates for measurement error, I adjust student test scores(\begin{math} \hat{\gamma_i} \end{math}) by

\begin{equation}
\hat{\gamma_i} = \hat{\gamma_i} * \frac{1}{\sqrt{r}}
\end{equation}

where \begin{math}r\end{math} is the reliability score of the wave \footnote{Other proceedures multiply each country by their own reliability measure for each year-subject pair \citep{anna2016_global}. The realibility estimates are calculated using Item Response Theory (IRT) analogues of traditional estimates of Person separation reliability such as internal consistency. Unfortunately, PISA 2000 did not provide any reliability measure separately for each country and PISA 2015 has to yet release their own. At the moment of writing this paper, they were unavailable. For this reason we implement the analysis following the original work of \citet{reardon2011}}. Each PISA survey provides a reliability indicator which we use accordingly. This yields estimates of the true gaps, and eliminates any bias in the trend that may arise from differential reliability of the tests.

After constructing the adjusted test score measurement, we estimate the SES dummy by calculating the weighted 90th and 10th quantiles for the SES composite index, and then generating a dummy of 1 for those above (including) the 90th percentile and 0 for those below (including) the 10th percentile.

We then fit

% Replace the Y_i with the chosen y from the previos equation.
\begin{equation}
\gamma_i = \alpha_{j[i]} + \beta_{j[i]} * SES_i + \epsilon_i,\ \text{for} \ i \ \text{= 1, 2, ...,} \ n \ \text{for each country} \ j
\end{equation}

% Try running also a linear model together with the multilevel model and ompcare results
% Brunno suggested this because countries which might have a very different SES estimate
% might be moved more towards the average.

% mod2 <-
%   lmer(adj_pvnum ~ escs_dummy + (1 + escs_dummy | country),
%        data = .x,
%        weights = .x[[weights_var]])

where \(SES_i\) is whether the student is in the top/bottom SES dummy and we allow both \(\alpha_i\) and \(\beta_i\) to vary by country \(j\). We implement this separately for each wave and weight by the wave-specific student sample weights.

Finally, we calculate the SES achievement gap for each country by extracting the fitted \(\alpha\) and \(\beta\) for each country \(j\) and calculating the difference of the predicted score of high and low SES.

\begin{equation}
\begin{split}
\quad \text{High SES}_j = \alpha_j + \beta_j \\
\quad \text{Low SES}_j = \alpha_j \\
\quad \text{SES gap}_j = \text{High SES}_j - \text{Low SES}_j
\end{split}
\end{equation}

We also calculate the standard error of this difference and use it to create uncertainty intervals in the estimation of time trends. We fit a multilevel rather than a linear model because by pooling the information together, we weight countries appropriately to their sample size. Given that including the SES \emph{dummy} reduces the sample size considerably, we want to be able to estimate each country-difference as accurately as possible. For further exploration, we also compute the 90th/50th and 50th/10th SES gaps following the same method outlined above.
% Explain more in detail that it's a dummy and not three groups.

\section{Analysis and results}

\subsection{Descriptives}

<<escsdummy_charachteristics>>=
escs_dummy_creator <- function(df, probs) {
  
    map(df, function(.x) {
      
      conf <- if (unique(.x$wave) == "pisa2015") pisa2015_conf else pisa_conf
      weights_var <- conf$variables$weightFinal

      country_split <- split(.x, .x$country)
      
      country_list <- map(country_split, function(country) {
        print(unique(country$country))
        
        quan <- quantile_missing(country, weights_var, probs)
        
        # It's very important to create a variable that returns the number of observations of this dummy
        # For each country. Possibly to weight by the number of observations.
        country$escs_dummy <-
          with(country, case_when(escs_trend >= quan[2] ~ 1,
                                  escs_trend <= quan[1] ~ 0))
        country
      })
      
      .x <-
        enframe(country_list) %>%
        unnest(value)
      
      message(paste(unique(.x$wave), "data ready"))
      
      .x
    })
}

escs_data <- escs_dummy_creator(adapted_year_data, c(0.1, 0.9))

# Make recode the education variable into three categories
map_lgl(escs_data, ~ "HISEI" %in% names(.x))

escs_data[[1]]$high_edu_broad <- dplyr::recode(escs_data[[1]]$high_edu_broad, `6` = 7)

edu_calc <- function(df) {
  df %>%
  select(country, escs_dummy, high_edu_broad) %>%
  count(country, escs_dummy, high_edu_broad) %>%
  group_by(country, escs_dummy) %>%
  mutate(total_n = sum(n),
         perc = n / total_n * 100) %>%
  filter(country %in% countries, high_edu_broad %in% c(1, 7)) %>%
  select(country, escs_dummy, high_edu_broad, perc) %>%
  map_if(is_double, round, 2) %>%
  as_tibble() %>%
  filter(!is.na(escs_dummy)) %>%
  spread(high_edu_broad, perc) 
}

summary_data <-
  map(escs_data, edu_calc) %>%
  setNames(years) %>%
  enframer()
@

<<sample_size>>=
# Get sample counts for each dummy
sample_size_calc <- function(df, probs, selected = F, cnts = NULL) {
  
  stopifnot(selected & !is.null(cnts))
  
  if (selected) df <- map(df, ~ filter(.x, country %in% cnts))
  
  cnt_to_bind <-
    map(df, function(df) {
      
      print(unique(df$wave))
      conf <- if (unique(df$wave) == "pisa2015") pisa2015_conf else pisa_conf
      weights_var <- conf$variables$weightFinal
      
      split_df <- split(df, df$country)
      
      split_df_two <-
        map(split_df, ~ {
          # In some countries the quan can't be estimated because of very few obs.
          # The function doesn't stop but returns two NA's.
          quan <- quantile_missing(.x, weights_var, probs)
          
          # It's very important to create a variable that returns the number of observations of this dummy
          # For each country. Possibly to weight by the number of observations.
          .x$escs_dummy <-
            with(.x, case_when(escs_trend >= quan[2] ~ 1,
                               escs_trend <= quan[1] ~ 0))
          .x
        })
      unsplit_df <- split_df_two %>% enframe() %>% unnest(value)
      
      unsplit_df %>%
        count(country, escs_dummy) %>%
        filter(!is.na(escs_dummy)) %>%
        left_join(summarize(group_by(unsplit_df, country), total_n = n()), by = "country") %>%
        mutate(perc = paste0(round(n / total_n * 100, 0), "%")) %>%
        select(-total_n)
    })
  setNames(cnt_to_bind, seq(2000, 2015, 3)) %>%
    enframe() %>%
    unnest()
}

sample_tables_topbottom <- sample_size_calc(adapted_year_data, c(.1, .9), selected = TRUE, countries)
sample_tables_topmid <- sample_size_calc(adapted_year_data, c(.5, .9), selected = TRUE, countries)
sample_tables_midbottom <- sample_size_calc(adapted_year_data, c(.1, .5), selected = TRUE, countries)
@

% Previous table that had % of low and high education for low and high SES dummies

% <<table_escs, include = TRUE>>=
% summary_table <-
%   left_join(summary_data, sample_tables_topbottom) %>%
%   filter(name %in% c("2000", "2015")) %>%
%   arrange(country, name)
% 
% table_coming <-
%   summary_table %>%
%   select(-perc) %>%
%   gather(cats, vals, -(name:escs_dummy)) %>%
%   unite(all_vals, escs_dummy, cats, sep = "_") %>%
%   spread(all_vals, vals) %>%
%   map_at(c(3, 4, 6, 7), ~ {
%     .x[is.na(.x)] <- 0
%     paste0(round(.x, 0), "%")
%   }) %>%
%   map_if(is_double, as.character) %>%
%   data.frame() %>%
%   xtable::xtable()
% 
% addtorow <- list()
% addtorow$pos <- list(0)
% addtorow$command <- paste("\\hline \\
%                           & & & Low SES & & & High SES \\\\
%                           \\cmidrule(l){3-5}
%                           \\cmidrule(l){6-8}",
%                           paste0(
%                             c("Year",
%                               "Countries",
%                               "\\% Low Edu",
%                               "\\% High Edu",
%                               "Sample size",
%                               "\\% Low Edu",
%                               "\\% High Edu",
%                               "Sample size"),
%                             collapse = " & "),
%                           "\\\\ \\hline")
% 
% print(table_coming,
%       scalebox = '0.75',
%       floating = FALSE,
%       add.to.row = addtorow,
%       include.colnames = FALSE,
%       include.rownames = FALSE,
%       hline.after = nrow(table_coming),
%       caption.placement = "top",
%       caption = "SES sample size and ISCED composition")
% @

% New table only has sample size, average score and s.e.
<<table_escs, include = TRUE>>=

avg_performance <-
  list(results_math[[1]], results_math[[6]]) %>%
  set_names(c(2000, 2015)) %>%
  enframe() %>%
  unnest()

summary_table <-
  sample_tables_topbottom %>%
  mutate(escs_dummy = as.character(escs_dummy)) %>%
  filter(name %in% c("2000", "2015")) %>%
  left_join(avg_performance) %>%
  arrange(country, name)

table_coming <-
  summary_table %>%
  select(-perc) %>%
  gather(cats, vals, -(name:escs_dummy)) %>%
  unite(all_vals, escs_dummy, cats, sep = "_") %>%
  spread(all_vals, vals) %>%
  select(name, country, `0_n`, `0_Mean`, `0_s.e.`, `1_n`, `1_Mean`, `1_s.e.`) %>%
  mutate(`0_n` = as.character(`0_n`),
         `1_n` = as.character(`1_n`)) %>%
  xtable::xtable()

addtorow <- list()
addtorow$pos <- list(0)
addtorow$command <- paste("\\hline \\
                          & & & Low SES & & & High SES \\\\
                          \\cmidrule(l){3-5}
                          \\cmidrule(l){6-8}",
                          paste0(
                            c("Year",
                              "Countries",
                              "N",
                              "Avg score",
                              "S.E",
                              "N",
                              "Avg score",
                              "S.E"),
                            collapse = " & "),
                          "\\\\ \\hline")

print(table_coming,
      scalebox = '0.75',
      floating = FALSE,
      add.to.row = addtorow,
      include.colnames = FALSE,
      include.rownames = FALSE,
      hline.after = nrow(table_coming),
      caption.placement = "top",
      caption = "SES sample size and ISCED composition")
@

The first table shows a description of the sample size and mean score of both top and bottom SES groups for only the first and last time point. One main concern from the planned analysis is that getting the top 90th percentile and bottom 10th percentile would result in a small sample size. The table suggests that we have a reasonable number of respondents to actually estimate gaps accurately. Moreover, we can see that in all instances the bottom SES group has a lower score than all top SES groups.

We see that in some countries like Finland and Sweden the average low SES scores is actually above the average score of 0, suggesting their very equal countries. However, most countries, like Spain, Poland, Hungary and Germany, their average low SES scores are much lower than the country average, which is 0. We also see some countries with major changes from year 2000 to 2015, with, for example, Australia decreasing the low SES gap from 0.22 standard deviations to -0.15, well below the country average. In the next section we take a look at this in a more detailed fashion, considering all years in between.

<<merge_math_read>>=

# Function does a lot of things, but in short:

# Calculate the difference between the gap and together with it's joint s.e
# Also uncertainty intervals and returns a tibble with the difference between
# SES gaps with the adjusted SE difference + uncertainty intervals + the original
# data (the absolute numbers before the differences)

pisa_preparer <- function(df_math, df_read) {

descrip_math <- map(df_math, ~ rename(.x, mean_math = Mean, se_math = s.e.))
descrip_read <- map(df_read, ~ rename(.x, mean_read = Mean, se_read = s.e.))


reduced_data_math <-
  map2(descrip_math, years, function(.x, .y) {
    .x %>%
      mutate(wave = .y) %>%
      filter(!is.na(escs_dummy))
  }) %>%
  bind_rows() %>%
  as_tibble() %>%
  mutate(lower_math = mean_math - 1.96 * se_math,
         upper_math = mean_math + 1.96 * se_math)

reduced_data_read <-
  map2(descrip_read, years, function(.x, .y) {
    .x %>%
      mutate(wave = .y) %>%
      filter(!is.na(escs_dummy))
  }) %>%
  bind_rows() %>%
  as_tibble() %>%
  mutate(lower_read = mean_read - 1.96 * se_read,
         upper_read = mean_read + 1.96 * se_read)

reduced_data <- left_join(reduced_data_math,
                          reduced_data_read, by = c("country", "escs_dummy", "wave"))

# Merging math and reading data
test_data <-
  reduced_data %>%
  select(country, wave, escs_dummy, contains("mean")) %>%
  gather(test, score, contains("mean"))

math_data <-
  reduced_data %>%
  select(country, wave, escs_dummy, contains("math")) %>%
  gather(test_bound, bound, contains("lower"), contains("upper")) %>%
  select(-contains("math")) %>%
  right_join(filter(test_data, test == "mean_math"))

read_data <-
  reduced_data %>%
  select(country, wave, escs_dummy, contains("read")) %>%
  gather(test_bound, bound, contains("lower"), contains("upper")) %>%
  select(-contains("read")) %>%
  right_join(filter(test_data, test == "mean_read"))

all_data <- bind_rows(math_data, read_data)

# Calculate the joint standard error of the difference
math_se_data <-
  reduced_data %>%
  select(country, escs_dummy, wave, se_math) %>%
  spread(escs_dummy, se_math) %>%
    transmute(country, wave,
              se_diff_math = sqrt(abs(`1`^2 - `0`^2)))

read_se_data <-
  reduced_data %>%
  select(country, escs_dummy, wave, se_read) %>%
  spread(escs_dummy, se_read) %>%
  transmute(country, wave,
            se_diff_read = sqrt(abs(`1`^2 - `0`^2)))

se_data <- left_join(math_se_data, read_se_data)

# Calculate the different between the gap and together with it's joint s.e graph
# the absolut difference.

math_diff <-
  reduced_data %>%
  select(wave, country, escs_dummy, mean_math) %>%
  spread(escs_dummy, mean_math) %>%
  transmute(wave, country, diff_math = `1` - `0`)

read_diff <-
  reduced_data %>%
  select(wave, country, escs_dummy, mean_read) %>%
  spread(escs_dummy, mean_read) %>%
  transmute(wave, country, diff_read = `1` - `0`)

data_summaries <-
  math_diff %>%
  left_join(read_diff) %>%
  left_join(se_data) %>%
  transmute(wave, country, diff_math, diff_read,
           lower_math = diff_math - 1.96 * se_diff_math,
           lower_read = diff_read - 1.96 * se_diff_read,
           upper_math = diff_math + 1.96 * se_diff_math,
           upper_read = diff_read + 1.96 * se_diff_read)

differences <-
  data_summaries %>%
  select(wave, country, diff_math, diff_read) %>%
  gather(test, difference, starts_with("diff")) %>%
  mutate(type_test = ifelse(.$test == "diff_math", "math", "read"))

bounds_lower <-
  data_summaries %>%
  select(wave, country, contains("lower")) %>%
  gather(lower_bound, lower, lower_math, lower_read) %>%
  mutate(type_test = ifelse(grepl("math", .$lower_bound), "math", "read"))

bounds_upper <-
  data_summaries %>%
  select(wave, country, contains("upper")) %>%
  gather(upper_bound, upper, upper_math, upper_read) %>%
  mutate(type_test = ifelse(grepl("math", .$upper_bound), "math", "read"))

# Getting the original data in
original_math <-
  reduced_data_math %>%
  select(wave, everything(), -se_math) %>%
  gather(metric, value, -(wave:escs_dummy)) %>%
  unite(combination, escs_dummy, metric, sep = "_") %>%
  spread(combination, value) %>%
  mutate(type_test = "math")

original_read <-
  reduced_data_read %>%
  select(wave, everything(), -se_read) %>%
  gather(metric, value, -(wave:escs_dummy)) %>%
  unite(combination, escs_dummy, metric, sep = "_") %>%
  spread(combination, value) %>%
  mutate(type_test = "read")

# final data
complete_data <-
  left_join(differences, bounds_lower) %>%
  left_join(bounds_upper) %>%
  left_join(original_math) %>%
  left_join(original_read)
}

complete_data_topbottom <- pisa_preparer(results_math, results_read)
complete_data_topmid <- pisa_preparer(results_math_topmid, results_read_topmid)
complete_data_midbottom <- pisa_preparer(results_math_midbottom, results_read_midbottom)

complete_data_topbottom <- mutate(complete_data_topbottom, type = "90th/10th SES gap")
complete_data_topmid <- mutate(complete_data_topmid, type = "90th/50th SES gap")
complete_data_midbottom <- mutate(complete_data_midbottom, type = "50th/10th SES gap")
@

<<correlation_incomeineq, include = F, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
complete_data_topbottom %>%
  mutate(wave = as.character(wave)) %>%
  left_join(inequalityintsvy::economic_inequality, by = c("wave" = "year", "country")) %>%
  filter(indicators == "GINI") %>%
  group_by(country) %>%
  summarize(avg_diff = mean(difference, na.rm = T),
            avg_value = mean(value, na.rm = T)) %>%
  filter(avg_value < 8) %>%
  ggplot(aes(avg_value, avg_diff)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ splines::ns(x, 2), linetype = "longdash", se = F)
@

\subsection{Evolution of the achievement gap}
% TODO: Calculate the difference between 90/10 and then the ratio of this with the annual gain of one year of schooling (\citet{micklewright} did it).

\begin{figure}
\begin{center}
<<graphing_9010gaps, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
# 90/10 gaps acros countries
diff_increase_fun <- function(df) {
  
  # Average standard deviation increase
  data_ready <-
    df %>%
    select(wave, country, type_test, difference) %>%
    group_by(type_test) %>%
    split(.$country) %>%
    map(~ {
      .x <-
        spread(.x, wave, difference) %>%
        ungroup()
  
      year_vars <- sum(map_dbl(.x, is.numeric)) - 1
      years_subtract <- names(.x)[c(ncol(.x) - year_vars, ncol(.x))]
      years_subtract <- lapply(years_subtract, as.name)

      last_year <- rlang::new_quosure(years_subtract[[2]], env = .GlobalEnv)
      first_year <- rlang::new_quosure(years_subtract[[1]], env = .GlobalEnv)
      
      years_available <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        group_by(type_test) %>%
        summarise(yr_avaible = sum(!is.na(val))) %>%
        pull(yr_avaible)
      
      year_sd <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        split(.$type_test) %>%
        map_dbl(~ bootstrapper(.x, mad(val, na.rm = T), B = 100) %>% .[[2, 2]]) %>%
        round(2) * 100

      
      .x %>%
        map_if(is_double, round, 3) %>%
        as_tibble() %>%
        transmute(type_test,
                  country,
                  diff = round(((!!last_year) - (!!first_year)), 1),
                  sd_year = year_sd,
                  diff_lower = diff - 1 * year_sd,
                  diff_upper = diff + 1 * year_sd,
                  years_available = years_available)
    })
  data_ready
}

diff_data <-
  diff_increase_fun(complete_data_topbottom) %>%
  enframer("country") %>%
  filter(country %in% countries) %>%
  select(country, type_test, diff) %>%
  split(.$type_test) %>%
  map(~ .x %>% select(-type_test) %>% deframe())

lm_data <- function(df) {
  lm(log(difference) ~ wave, data = df) %>%
    broom::tidy() %>%
    mutate(estimate = exp(estimate))
}

ordered_cnt <-
  complete_data_topbottom %>%
  filter(type_test == "math") %>%
  select(wave, country, difference) %>%
  filter(country %in% countries) %>%
  split(.$country) %>%
  map(lm_data) %>%
  enframer("country") %>%
  filter(term == "wave") %>%
  arrange(-estimate) %>%
  pull(country)

pooled_trendline <-
  complete_data_topbottom %>%
  mutate(country = factor(country, levels = ordered_cnt, ordered = TRUE)) %>%
  filter(!is.na(country))

pooled_trendline %>%
  filter(type_test == "math") %>%
  ggplot(aes(as.character(wave), difference)) +
  geom_point() +
  geom_linerange(aes(ymin = 0, ymax = difference))+
  geom_line(data = pooled_trendline, stat = "smooth", method = "lm", aes(group = 1),
            formula = y ~ splines::ns(x, 2), size = 0.7,
            colour = "red") +
  facet_wrap(~ country, ncol = 5) +
  scale_y_continuous(name = "90/10 gap in SD", expand = c(0, 0), lim = c(0, 3)) +
  scale_x_discrete(name = NULL, breaks = c(2000, 2009, 2015)) +
  ggthemes::theme_few() +
  theme(panel.spacing = unit(1, "lines"),
        panel.grid.major.y = element_line(colour = "grey")) +
  ggtitle("Evolution of the 90/10 achievement gap")
@
\caption{Evolution of the achievement gap for selected countries}
\end{center}
\end{figure}

We start by look at the achievement for some countries in figure 2. We plot only mathematics for each country and also a quadratic trend spline for \emph{both mathematics and literacy} pooled. Some countries have increased their achievement very strongly. For example, France, Austria and surprisingly Sweden have very steep slopes. France increasde the gap by roughly \Sexpr{diff_data$math[["France"]]} standard deviations, Austria by \Sexpr{diff_data$math[["Austria"]]} and Sweden by \Sexpr{diff_data$math[["Sweden"]]}. This pattern happens similarly for literacy. For example, France has an increase of \Sexpr{diff_data$read[["France"]]}. For such a short period of time, the magnitud of these increases are reasonably big.

Given that no one has estimated the evolution of the gap we can't cross-check how other empirical estimations put France at. However, we can take \citet{micklewright} as the closest reference which also finds that France was a low dispersion country in 2000. However, there's no evidence on what happened over time. Luckily, the work of \citet{bernardi2016} did study the relationship of social origin effects (broadly speaking, not in terms of achievement gaps) in France and found that they increased in the last decades.

Other countries have reasonable increases such as Finland and Hungary, with increases of nearly \Sexpr{diff_data$math[["Finland"]]} and \Sexpr{diff_data$math[["Hungary"]]}, respectively. Aside from these countries, there are other cases that have no change at all, specifically, Canada, Netherlands and Spain. Canada excels here not only because the gap has been stable over time, but because it has the smallest gap of all countries presented here. It's nearly 0.5 standard deviations in 2000 and it increased only by \Sexpr{diff_data$math[["Canada"]]} in 2015. We can't really say Italy has had a significant since it has a sort of wiggly pattern that looks like it cancels itself out.

On the other hand, we do have some countries which show a decrease in the SES achievement gap. United Kingdom decreased by about \Sexpr{diff_data$math[["United Kingdom"]]}, Poland by \Sexpr{diff_data$math[["Poland"]]}, and Denmark by \Sexpr{diff_data$math[["Denmark"]]}. However, the most notable cases are the United States and Germany. These two countries show a very high level of dispersion in the year 2000 with SES gaps of over 2 standard deviations. But in the 15-year time trend both countries reduced the gaps by \Sexpr{diff_data$math[["United States"]]} and \Sexpr{diff_data$math[["Germany"]]} respectively. Their distinctively big gaps in 2000 also show up in the work of \citet{micklewright}. This corroborates the findings of \citet{reardon_portilla}, which found a decreasing gap for kindergarteners. This decline is evident also for 15 year olds, suggesting it might be more of an institutional change rather than a specific grade-level policy.

Analyzing this graph we might naively conclude that these trends are not very steep and they should not be very important to consider. However, remember that the Y axis is measured in standard deviations. Small changes are actually very huge in practical terms. Take the case of Sweden. The slope doesn't look that steep but in reality it increased the gap from 1 standard deviation in 2000 to around 1.5 standard deviation in 2015. The actual difference is of about \Sexpr{diff_data$math[["Sweden"]]}. Now that we know that, the trends of Poland, United States, France and Germany are particularly shocking.

<<us_sd_start>>=
us_math_2000 <-
  filter(complete_data_topbottom, wave == 2000, country == "United States", type_test == "math") %>%
  .[["difference"]]

us_math_2000_lower <-
  filter(complete_data_topbottom, wave == 2000, country == "United States", type_test == "math") %>%
  .[["lower"]]

us_math_2000_upper <-
  filter(complete_data_topbottom, wave == 2000, country == "United States", type_test == "math") %>%
  .[["upper"]]
@
We find that the initial gap for the U.S in 2000 is \Sexpr{round(us_math_2000, 2)} varying between \Sexpr{round(us_math_2000_lower, 2)} and \Sexpr{round(us_math_2000_upper, 2)}. This gap is much higher than found in previous studies, but again, we don't know much previous estimates vary and nobody has really studied the 15-year old achievement gap precisely. All country-level studies pool many studies together and control for age, removing the age-specific gap effect.

Figure 3 below takes a more direct approach and looks at the percentage change from the first and last timepoint available. Each data point has been computed together with it's 50\% and 95\% uncertainty interval \footnote{Each of these uncertainty intervals were computed using a 500-replicate bootstrap}.

% How to output data frames are latex tables?
<<perc_increase_tables>>=
# Show the rates at which is increasing/decreasing
perc_increase_fun <- function(df) {
  
  # Average standard deviation increase
  data_ready <-
    df %>%
    select(wave, country, type_test, difference) %>%
    group_by(type_test) %>%
    split(.$country) %>%
    map(~ {
      .x <-
        spread(.x, wave, difference) %>%
        ungroup()
  
      year_vars <- sum(map_dbl(.x, is.numeric)) - 1
      years_subtract <- names(.x)[c(ncol(.x) - year_vars, ncol(.x))]
      years_subtract <- lapply(years_subtract, as.name)

      last_year <- rlang::new_quosure(years_subtract[[2]], env = .GlobalEnv)
      first_year <- rlang::new_quosure(years_subtract[[1]], env = .GlobalEnv)
      
      years_available <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        group_by(type_test) %>%
        summarise(yr_avaible = sum(!is.na(val))) %>%
        pull(yr_avaible)
      
      year_sd <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        split(.$type_test) %>%
        map_dbl(~ bootstrapper(.x, mad(val, na.rm = T), B = 100) %>% .[[2, 2]]) %>%
        round(2) * 100

      
      .x %>%
        map_if(is_double, round, 3) %>%
        as_tibble() %>%
        transmute(type_test,
                  country,
                  perc_diff = round(((!!last_year) - (!!first_year)) * 100, 1),
                  sd_year = year_sd,
                  diff_lower = perc_diff - 1 * year_sd,
                  diff_upper = perc_diff + 1 * year_sd,
                  years_available = years_available)
    })
  data_ready
}
 
top_bottom_perc <- perc_increase_fun(complete_data_topbottom)
top_mid_perc <- perc_increase_fun(complete_data_topmid)
mid_bottom_perc <- perc_increase_fun(complete_data_midbottom)
 
# Gap is closing at an average of the variable diff per year.
@

\begin{figure}
\begin{center}
<<graphing_perc_increase, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
perc_graph <- function(df, test, title, subtitle = NULL) {
  df %>%
  enframe(name = "country") %>%
  unnest(value) %>%
  filter(country %in% countries) %>%
  select(-country1, -years_available) %>%
  mutate(diff_95_lower = perc_diff - 2*sd_year,
         diff_95_upper = perc_diff + 2*sd_year) %>%
  setNames(c("Country", "Type of test", "Average % difference", "Average SD",
             "Lower 50% bound", "Upper 50% bound", "Lower 95% bound", "Upper 95% bound")) %>%
  filter(`Type of test` == test) %>%
  arrange(`Average % difference`) %>%
  mutate(Country = ordered(forcats::as_factor(Country)),
         Country_num = as.numeric(Country)) %>%
  ggplot(aes(Country, `Average % difference`, fill = `Average % difference` > 0)) +
  geom_hline(yintercept = 0, linetype = "longdash") +
  geom_point() +
  geom_ribbon(aes(x = Country_num, ymin = `Lower 95% bound`, ymax = `Upper 95% bound`), alpha = 0.3) +
  geom_ribbon(aes(x = Country_num, ymin = `Lower 50% bound`, ymax = `Upper 50% bound`), alpha = 0.2) +
  geom_linerange(aes(ymin = 0, ymax = `Average % difference`,
                     colour = `Average % difference` > 0), alpha = 0.4) +
  scale_y_continuous(name = "Avg % increase/decrease",breaks = seq(-160, 160, 40)) +
  scale_fill_discrete(guide = FALSE) +
  scale_colour_discrete(guide = FALSE) +
  coord_cartesian(ylim = c(-160, 160)) +
  ggtitle(title, subtitle) +
  ggthemes::theme_few() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
}
 
perc_graph(top_bottom_perc, "math", "90/10 achievement gap", "Percentage change from 2000 to 2015")
# m2 <- perc_graph(top_mid_perc, "90/50")
# m3 <- perc_graph(mid_bottom_perc, "50/10")

# gridExtra::grid.arrange(m1, m2, m3, nrow = 1)
@
\caption{Percentage change in the achievement gap from 2000 to 2015}
\end{center}
\end{figure}

Generally speaking, we see that most countries increased their achievement gap over time. France had an average increase of about 80\% since 2000 varying down to 40\%, whereas Germany had a similar figure but decreasing. Many of the countries we saw before that didn't have a very steep slope, such as Hungary or Australia, in fact had increases of about 40\% of their gap. In contrast, we see that the U.S and Poland had also quite significant decreases of about 40\%. The benefit of presenting these estimates this way is that we can actually asses the uncertainty of each calculation, and we do find that some of these estimates have wide variability. Despite this, most countries show a clear sign of either decreasing or increasing.

% Code chunks for the same plots as above for reading. Available upon request.
<<evolution_reading, eval = F>>=
# See below that reading graph is upon request. This is the one.

pooled_trendline %>%
  filter(type_test == "read") %>%
  ggplot(aes(as.character(wave), difference)) +
  geom_point() +
  geom_linerange(aes(ymin = 0, ymax = difference))+
  geom_line(data = pooled_trendline, stat = "smooth", method = "lm", aes(group = 1),
            formula = y ~ splines::ns(x, 2), size = 0.7,
            colour = "red") +
  facet_wrap(~ country, ncol = 5) +
  scale_y_continuous(name = "90/10 gap in SD", expand = c(0, 0), lim = c(0, 3)) +
  scale_x_discrete(name = NULL, breaks = c(2000, 2009, 2015)) +
  coord_fixed() +
  ggthemes::theme_few() +
  theme(panel.spacing = unit(1, "lines"),
        panel.grid.major.y = element_line(colour = "grey")) +
  ggtitle("Evolution of the 90/10 achievement gap")

perc_graph(top_bottom_perc, "read", "90/10 achievement gap", "Percentage change from 2000 to 2015")
@

Something reassuring is that mathematics and reading (not presented) follow basically the same trend across all countries \footnote{Reading had an even bigger decrease for similar countries, and a much smaller increase. The previos two graphs for reading are available upon request}. This means that the result is not an artifact of chance. However, it's important to disentangle where is this gap originating from. Is this because the top are improving why the bottom decreases? Or is it that the bottom is catching up? Up next we plot the same graph but show the divergent patterns between high/low SES origins.

\subsection{Source of the achievement gap}

% Add confidence intervals
\begin{figure}
\begin{center}
<<rate_increase/decrease, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
# You left off here. Plot the gap for 1 and 0 for all countries in the graph before.
complete_data_topbottom %>%
  filter(country %in% countries) %>%
  mutate(country = factor(country, levels = ordered_cnt, ordered = TRUE)) %>%
  select(wave, country, matches("*._math$")) %>%
  gather(ses, gap_size, matches("^\\d_mean_math$")) %>%
  separate(ses, c("ses", "delete"), sep = 2) %>%
  mutate(ses = gsub("_", "", ses)) %>%
  filter(complete.cases(.)) %>%
  # gather(lower_bound, lower, matches("\\d_lower")) %>%
  # gather(upper_bound, upper, matches("\\d_upper"))
  ggplot(aes(as.factor(wave), gap_size, group = ses, colour = ses, shape = ses)) +
  geom_point(size = 2, alpha = 0.4) +
  geom_line(alpha = 0.4) +
  geom_line(stat = "smooth", method = "lm", aes(group = 1),
            formula = y ~ splines::ns(x, 1), linetype = "longdash",
            colour = "black") +
  scale_y_continuous(name = "Standardized test scores (mean 0)") +
  scale_x_discrete(name = NULL, breaks = c(2000, 2009, 2015)) +
  scale_colour_discrete(name = NULL, labels = c("Low SES", "High SES")) +
  scale_shape_discrete(name = NULL, labels = c("Low SES", "High SES")) +
  ggtitle("Evolution of the achievement gap by top/bottom groups") +
  # geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1, alpha = 0.4) +
  # geom_hline(yintercept = 0, linetype = "longdash") +
  # coord_cartesian(ylim = c(0, 3)) +
  facet_wrap(~ country, ncol = 5) +
  theme_few() +
  theme(panel.spacing = unit(1, "lines"),
        legend.position = "bottom")
@
\caption{Evolution of the achievement gap for separate SES groups}
\end{center}
\end{figure}


Figure 4 shows the evolution for both Low and High SES groups separetly. The middle line is a summary line showing whether one of the groups is growing/shrinking faster than the other. We find plenty of variation in these patterns. For example, in the United States the top seems to be equalizing much stronger than than the bottom is catching up. The U.K seems to be following the same path as the United States as well. On the other hand, in Poland the gap seems to be closing because the bottom SES group is catching up much faster. The Netherlands shows a similar pattern as the U.S, U.K patterns but upon closer inspection the explanation is very different. We see that the slope is negative (like in the previous two countries) but that's because the low SES group is decreasing at a greater rate than the high SES is decreasing.

Finally, we pay attention to the flat summary lines. These lines should be interpreted with caution because it doesn't mean that the gap is not increasing. Denmark, Belgium, Netherlands, Norway and Spain show a flat line because the gap is growing very little, if at all. On the other hand, Sweden, France, Finland, New Zealand, Austria, among other countries, show a flat line because both groups are distancing themselves at a very similar rate. These results highlight the importance of not only summarizing average achievement gaps. The source of these gaps vary greatly between countries and we see how each of these patterns contibutes to the overall inequality of a country.

Ths source of this gap can be deconstructed further into two broader gaps. We want to know if these gaps have increased because the 90th SES group has distanced itself from the 50th SES group or because the middle has been also distancing itself from 10th SES group. For example, we're interested in searching which gap is bigger between countries, the 90th/50th or the 50th/10th? Moreover, are some of these gaps contributing more to the 90th/10th gap we saw earlier? Up next we plot all the combinations of the 90th/50th/10th gaps and pay attention to the magnitude of each gap in figure 5. Because we visualize three plots for every country, we only plot a selected number of countries that represent the overall patterns from the previous graphs \footnote{United States and Germany show a decrease, France shows a steep increase and Denmark shows no significant change.}.

\begin{figure}
\begin{center}
<<graphing_allgaps, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=

# Comparing all gaps across countries
complete_data_topbottom %>%
  bind_rows(complete_data_topmid) %>%
  bind_rows(complete_data_midbottom) %>%
  filter(country %in% c("United States", "Denmark", "France", "Germany"),
         type_test == "math") %>%
  mutate(type = factor(type,
                       levels = c("90th/10th SES gap", "90th/50th SES gap", "50th/10th SES gap"),
                       ordered = TRUE)) %>%
  ggplot(aes(as.factor(wave), difference, group = type_test)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) +
  geom_linerange(aes(ymin = 0, ymax = difference)) +
  geom_line(stat = "smooth", method = "lm", aes(group = 1),
            formula = y ~ splines::ns(x, 2), size = 0.7,
            colour = "red") +
  geom_point(size = 0.5, alpha = 0.4) +
  scale_y_continuous(name = "90/10 gap in SD", expand = c(0, 0), lim = c(0, 3)) +
  scale_x_discrete(name = NULL, breaks = c(2000, 2009, 2015)) +
  coord_cartesian(ylim = c(0, 3)) +
  ggtitle("Comparison of the achievement gap for three socio-economic groups") +
  facet_grid(country ~ type) +
  ggthemes::theme_few() +
  theme(panel.spacing = unit(1, "lines"))
@
\caption{Evolution of 90/50/10 SES gaps for selected countries}
\end{center}
\end{figure}

We start off with Denmark. Generally speaking, we find that the 50th/10th gap is contributing more than the 90th/50th gap as the gap is bigger in mathematics. Furthermore, we find, just as in the 90th/10th SES gap, that there isn't a significant decrease \footnote{With the exception of reading in the 50th/10th SES gap which seemed to decrease from nearly 1.5 to 1 standard deviation.}. France shows a similar pattern as Denmark in that the 50th/10th SES gap is the main contributer and that the three gaps have the similar trend. 

Germany and U.S, on the other hand, show a very different landscape. For example, Germany, shows that the 90th/10th gap is primarily driven by the 50th/10th SES gap and that the slopes of the 90th/50th gap is much weaker than the other two gaps. This means that top/middle SES groups have shrunk much less than the other groups. The big catching up is actually coming from the middle/bottom SES groups. However, we don't know if this is because the bottom is catching up or that the middle is coming down. Based on the gap plots from above, we can infer that it is because the bottom is catching up rapidly because against the 90th SES group, it is increasing steeply every year.

The U.S shows a different pattern from all other countries. Both the 90th/50th/10th gaps seem to contribute rather similarly to the overall 90th/10th gap (although 50th/10th is marginally higher) but more interestingly, the 90th/50th gap has stagnated in the last 15 years. The top/middle groups have a relatively big gap and it hasn't changed at all. On the other hand, the steep decrease we saw for the U.S is coming exclusively from the 50th/10th gap shrinking. The reason, nonetheless, might be different from the German case, where it's probable that the bottom is catching up. Here, as in the 90th/10th gap, the middle might be 'dumbing' down closer to the low SES group. The big takeaway from the U.S is that the decrease of inequality is coming from the shrinking of the 50/10 gap.

In a more convenient way, we can inspect whether there is a lot of variance in the rate at which top/bottom groups are changing in figure 6.

<<rate_change>>=
 
avg_increase_fun <- function(df, class) {

# Average standard deviation increase
  data_ready <-
    df %>%
    select(wave, country, type_test, contains("mean_math")) %>%
    gather(metric, value, -(wave:type_test)) %>%
    separate(metric, c("ses", "test"), sep = 2) %>%
    spread(test, value) %>%
    mutate(ses = gsub("_", "", ses)) %>%
    filter(type_test == "math", ses == class) %>%
    split(.$country) %>%
    map(~ mutate(.,
                 diff = c(diff(mean_math, lag = 1), NA),
                 perc = round(diff / mean_math, 2) * 100,
                 perc_pos = mean(perc > 0, na.rm = T))) %>%
    enframe() %>%
    unnest(value) %>%
    split(.$country)
  
    map2(data_ready, names(data_ready), ~ {

      print(.y)
      
      mean_df <-
        bootstrapper(.x, mean(diff, na.rm = T), B = 500) %>%
        filter(type == "bootstrap") %>%
        rename(mean = value)

      sd_df <-
        bootstrapper(.x, sd(diff, na.rm = T), B = 500) %>%
        filter(type == "bootstrap") %>%
        rename(sd = value)
      
      suppressMessages(
        left_join(mean_df, sd_df) %>%
        mutate(lower_bound = mean - 1 * sd,
               upper_bound = mean + 1 * sd)
      )
    }) %>%
    enframe() %>%
    unnest(value)
}

avg_sd_increase_high <- avg_increase_fun(complete_data_topbottom, 1)
avg_sd_increase_low <- avg_increase_fun(complete_data_topbottom, 0)
@

\begin{figure}
\begin{center}
<<rate_change_graph, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
 
full_data <-
  left_join(select(avg_sd_increase_high, name, mean),
            select(avg_sd_increase_low, name, mean), by = "name") %>%
  mutate(continent = ifelse(name %in% countries, "my_cnt", "other_cnt"))

colnames(full_data) <- c("country", "high_increase", "low_increase", "continent")

lims <- list(xlim = c(-0.15, 0.25), ylim = c(-0.25, 0.25))

rect_data <- tibble(xst = c(lims$xlim[1], 0),
                    xen = c(0.0, lims$xlim[2]),
                    yst = c(0.0, lims$ylim[1]),
                    yen = c(lims$ylim[2], 0),
                    colour = c("red", "green"))

full_data %>%
  ggplot(aes(low_increase, high_increase), alpha = 0.2) +
  geom_rect(data = rect_data, aes(xmin = xst,
                                  xmax = xen,
                                  ymin = yst,
                                  ymax = yen),
            fill = rect_data$colour,
            alpha = 0.2,
            inherit.aes = FALSE) +
  geom_line(stat="smooth", method = "lm", se = FALSE, alpha = 0.5, colour = "grey", size = 1,
            linetype = "longdash") +
  geom_point(alpha = 0.2) +
  geom_point(data = filter(full_data, continent == "my_cnt"), colour = "red", alpha = 0.7) +
  geom_line(data = filter(full_data, continent == "my_cnt"), colour = "red", alpha = 0.4,
            stat="smooth", method = "lm", se = FALSE, alpha = 0.5, colour = "red", size = 1) +
  geom_text_repel(data = filter(full_data, continent == "my_cnt"),
                  aes(label = country), box.padding = unit(2.7, "lines")) +
  geom_vline(xintercept = 0, alpha = 0.5) +
  geom_hline(yintercept = 0, alpha = 0.5) +
  xlim(lims$xlim) +
  ylim(lims$ylim) +
  coord_cartesian(expand = FALSE) +
  annotate(geom = "text", x = 0.15, y = -0.2,
           label = "Low SES is catching up \n faster than High SES",
           fontface = 2, size = 3) +
  annotate(geom = "text", x = -0.075, y = 0.20,
           label = "High SES is increasing  \n faster than Low SES is catching up",
           fontface = 2, size = 3) +
  labs(x = "Average increase of low SES in SD", y = "Average increase of high SES in SD") +
  theme_minimal()
@
\caption{Rate at which top/bottom SES groups are catching up for the 90/10 SES gap}
\end{center}
\end{figure}

We see that there are more countries where High SES is increasing inequality faster than low SES is catching up (red panel) but there's also a fair share where low SES is catching up faster, such as the United States and Germany. We see a negative relationship where the faster the low SES catch up the slower the High SES decrease. This is very interesting because it suggests that there's a trend for countries to have the bottom SES groups are climbing upwards, a trait of meritocracy. Equally important, we see very few countries where low SES are decreasing (so going even further down) and High SES is also decresing (bottom left panel). On the other hand, we do see more ocuntries where the both groups are increasing (top right panel). We plot all remaining countries in the back, together with a trendline and we see that the relation holds for all PISA countries.

But, similar as before, we don't know which group is causing the decrease/increase of the gap in the 90th/50th and 50th/10th gap. For that we plot the evolution of these gaps in figure 7.

\begin{figure}
\begin{center}
<<graphing_ses_growth, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
# Graphing how the top/bottom are evolving over time instead of absolute difference

complete_data_topbottom %>%
  bind_rows(complete_data_topmid) %>%
  bind_rows(complete_data_midbottom) %>%
  filter(country %in% c("United States", "Denmark", "France", "Germany"), type_test == "math") %>%
  select(wave, country, type_test, type, contains("math")) %>%
  mutate(type = factor(type,
                       levels = c("90th/10th SES gap", "90th/50th SES gap", "50th/10th SES gap"),
                       ordered = TRUE)) %>%
  gather(score, value, -(wave:type)) %>%
  separate(score, c("ses", "score"), sep = 2) %>%
  spread(score, value) %>%
  ggplot(aes(as.factor(wave), mean_math, group = ses, colour = ses, shape = ses)) +
  geom_line(alpha = 0.4) +
  geom_point(size = 2, alpha = 0.4) +
  coord_cartesian(ylim = c(-1, 2)) +
  scale_y_continuous(name = "Standardized test scores (mean 0)") +
  scale_x_discrete(name = NULL, breaks = c(2000, 2009, 2015)) +
  scale_colour_discrete(name = NULL, labels = c("Low SES", "High SES")) +
  scale_shape_discrete(name = NULL, labels = c("Low SES", "High SES")) +
  ggtitle("Evolution of the top/bottom groups by different gaps") +
  facet_grid(country ~ type) +
  theme_few() +
  theme(panel.spacing = unit(1, "lines"),
        legend.position = "bottom")
@
\caption{Evolution of the SES gaps for top/bottom groups}
\end{center}
\end{figure}

With Denmark there's no average change across all years. However, for France, we see that the gap is growing much faster for the 50th/10th SES gap. For Germany we see that the gap is closing in all three groups although much more strongly for the 50th/10th SES gap. It looks like the 50th/10th gap is mainly driving the changes in the gaps for most of the countries that actually see a change over time.  For the U.S, there's very little change in the 90th/50th SES gap, with most of the change coming from the 50th/10th gap.

Given that we have the data for the average performance for each country and the achievement gap, we can also investigate whether there's a tradeoff between the average country performance and the widening of the achievement gap and if it stands over time. One particular topic that has been researched in the past is whether improving the overall performance of a country compromises the equality of the educational system. For example, in order to improve the average score in, let's say, mathematics, tracking can improve the average score by making children in the higher trackers perform better, raising the overall performance. This, however, can come at a price. If tracking actually benefits the top but doesn't increase the performance of the bottom tracks then we see a net increase of inequality accompanied with an increase in the overall performance. We plot this relationship in figure 8.

\subsection{Performance-equality tradeoff}
<<graphing_achievement_disparity, cache = T>>=

country_scores <-
  map(adapted_year_data, ~ {
  if (unique(.x$wave) == "pisa2015") {
    intsvy::pisa2015.mean.pv("MATH", by = "country", data = .x)
  } else {
    intsvy::pisa.mean.pv("MATH", by = "country", data = .x)
  }
}) %>% setNames(seq(2000, 2015, 3))

country_scores <-
  enframe(country_scores, name = "wave") %>%
  unnest() %>%
  mutate(wave = as.double(wave))

data_to_plot <-
  left_join(complete_data_topbottom, country_scores, by = c("wave", "country")) %>%
  select(wave, country, type_test, difference, Mean) %>%
  filter(type_test == "math")

data_to_plot %>%
  ggplot(aes(scale(Mean), difference)) +
  geom_point() +
  geom_smooth()
@

<<correlation_performance_inequality>>=
correlation <-
  data_to_plot %>% group_by(wave) %>%
  summarize(cor = cor(difference, Mean, use = 'complete.obs')) %>%
  pull(cor)
@

\begin{figure}
\begin{center}
<<avgperformance_inequality, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
data_to_plot %>%
  ggplot(aes(scale(Mean), difference)) +
  geom_smooth(method = "lm") +
  geom_point() +
  scale_y_continuous(name = "90/10 achievement gap") +
  scale_x_continuous(name = "Average performance standardized") +
  ggtitle("Relationship between average performance and achievement gap") +
  facet_wrap(~ wave, nrow = 2) +
  theme_few()
@
\caption{Relationship between 90/10 achievement gap and average performance in mathematics}
\end{center}
\end{figure}

For the past 15 years we see a very strong correlation suggesting that countries that perform very well in PISA have actually very low achievement gaps (or the other way around) \footnote{We graph all countries-years pooled as well and the relationship is identical}. The correlations are between \Sexpr{round(max(correlation), 2)} and \Sexpr{round(min(correlation), 2)}. This confirms the theoretical and empirical frameworks suggested by \citet{werfhorst_mijs}. However, what they didn't really go in depth was whether this corelation is strongest for some countries over time. With the data available we can look at the evolution separately for many countries. We plot it up next in figure 9.

% Add confidence intervals
\begin{figure}
\begin{center}
<<country_achievement_and_inequality, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
data_to_plot %>%
  mutate(Mean = scale(Mean),
         country = factor(country, levels = ordered_cnt, ordered = TRUE)) %>%
  gather(type, value, difference, Mean) %>%
  filter(country %in% countries) %>%
  ggplot(aes(as.character(wave), value, group = type, colour = type, shape = type)) +
  geom_point(size = 2, alpha = 0.4) +
  geom_line(alpha = 0.4) +
  scale_y_continuous(name = "Test scores in SD") +
  scale_x_discrete(name = NULL, breaks = c(2000, 2009, 2015)) +
  scale_colour_discrete(name = NULL, labels = c("Achievement gap", "Avg performance")) +
  scale_shape_discrete(name = NULL, labels = c("Achievement gap", "Avg performance")) +
  ggtitle("Evolution of the top/bottom groups by different gaps") +
  facet_wrap(~ country, ncol = 5) +
  theme_few() +
  theme(panel.spacing = unit(1, "lines"),
        legend.position = "bottom")
@
\caption{Time trends of achievement gap and average achievement between 2000 and 2015}
\end{center}
\end{figure}

% Add descriptive table with average test scores, degree of tracking, level of income inequality, among other things.

Looking at figure 9, we see a strong correspondence between the two variables. In countries like France we see quite a functional form between both inequality and performance. As average performance plummets, the achievement gap is increasing. This pattern is also seen in Austria, Australia and Germany. The other obvious pattern is the opposite trend. We see countries like Poland, Finland, Canada and less pronounced, Italy, where this pattern is evident. The surprising case here is the United States. We see that as the average performance has been decreasing, the average achievement gap has been decreasing as well. In fact, among the few countries we should find something that resembles this pattern should be the U.S because it doesn't have a strict institutionalized tracking system. However, the explanation behind this pattern is very speculative.

Finally, the last notable pattern is that in some countries the average performance is so high that it actually overperforms the achievement gap. Only Finland, Canada and Netherlands (three very equal countries) have their average performance in standard deviations above their level of inequality, which coincidentially, are countries that have the lower leven of inequalities among the ones presented here.

<<next_steps>>=
# Next steps:

# Continue by doing the multilevel models to see what explains what. Include
# all indicators from the reardon/russian girl paper.
  
# Graph the increase in each country vs the increase/decrease of the economic inequality indicators
# Specially the 90/10

# Calculate how big is the gap between reading and math
  
# Continue with the PIRLS to see if there are specific patterns in 4th and 8th graders gap.
  
# Get each country trendline adjusted for the inequality indicators and place in the same country graph.

# Should I add the parent's education in the lm model to see how trends change adjusted for that?

# A weak welfare system, together with income inequality, what's their pattern?
# What if we put the school differentiation/tracking aspect in? Are there country groups based on these
# patterns.

# In countries where there is high differentiation/tracking, is there a jump in the evolution of the gap between PIRLS/TIMSS and PISA?
@

\bibliography{mybibliography.bib}

\pagebreak

\section{Appendix}

<<estimating_othergaps>>=
results_math_80 <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.8, 0.2))
results_read_80 <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.8, 0.2))
results_math_topmid_80 <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.8, 0.5))
results_read_topmid_80 <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.8, 0.5))
results_math_midbottom_80 <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.5, 0.2))
results_read_midbottom_80 <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.5, 0.2))

results_math_70 <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.70, 0.30))
results_read_70 <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.70, 0.30))
results_math_topmid_70 <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.70, 0.5))
results_read_topmid_70 <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.70, 0.5))
results_math_midbottom_70 <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.5, 0.30))
results_read_midbottom_70 <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.5, 0.30))

write_rds(results_math_80, "./data/math_80")
write_rds(results_read_80, "./data/read_80")
write_rds(results_math_topmid_80, "./data/math_topmid_80")
write_rds(results_read_topmid_80, "./data/read_topmid_80")
write_rds(results_math_midbottom_80, "./data/math_midbottom_80")
write_rds(results_read_midbottom_80, "./data/read_midbottom_80")

write_rds(results_math_70, "./data/math_70")
write_rds(results_read_70, "./data/read_70")
write_rds(results_math_topmid_70, "./data/math_topmid_70")
write_rds(results_read_topmid_70, "./data/read_topmid_70")
write_rds(results_math_midbottom_70, "./data/math_midbottom_70")
write_rds(results_read_midbottom_70, "./data/read_midbottom_70")

# results_math <- read_rds("./data/delete.Rdata")
# results_read <- read_rds("./data/delete_read.Rdata")
# results_math_topmid <- read_rds("./data/delete_math_topmid.Rdata")
# results_read_topmid <- read_rds("./data/delete_read_topmid.Rdata")
# results_math_midbottom <- read_rds("./data/delete_math_midbottom.Rdata")
# results_read_midbottom <- read_rds("./data/delete_read_midbottom.Rdata")

# results_math <- read_rds("./data/delete.Rdata")
# results_read <- read_rds("./data/delete_read.Rdata")
# results_math_topmid <- read_rds("./data/delete_math_topmid.Rdata")
# results_read_topmid <- read_rds("./data/delete_read_topmid.Rdata")
# results_math_midbottom <- read_rds("./data/delete_math_midbottom.Rdata")
# results_read_midbottom <- read_rds("./data/delete_read_midbottom.Rdata")

@

<<eval = F>>=
results_math_80 <- read_rds("./paper/data/math_80.Rdata")
results_read_80 <- read_rds("./paper/data/read_80.Rdata")
results_math_topmid_80 <- read_rds("./paper/data/math_topmid_80.Rdata")
results_read_topmid_80 <- read_rds("./paper/data/read_topmid_80.Rdata")
results_math_midbottom_80 <- read_rds("./paper/data/math_midbottom_80.Rdata")
results_read_midbottom_80 <- read_rds("./paper/data/read_midbottom_80.Rdata")

results_math_70 <- read_rds("./paper/data/math_70.Rdata")
results_read_70 <- read_rds("./paper/data/read_70.Rdata")
results_math_topmid_70 <- read_rds("./paper/data/math_topmid_70.Rdata")
results_read_topmid_70 <- read_rds("./paper/data/read_topmid_70.Rdata")
results_math_midbottom_70 <- read_rds("./paper/data/math_midbottom_70.Rdata")
results_read_midbottom_70 <- read_rds("./paper/data/read_midbottom_70.Rdata")
@

\begin{figure}
\begin{center}
<<graph_all_gaps,  include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
complete_data_topbottom_80 <-
  pisa_preparer(results_math_80, results_read_80) %>%
  mutate(type = "80th/20th SES gap")

complete_data_topmid_80 <-
  pisa_preparer(results_math_topmid_80, results_read_topmid_80) %>%
  mutate(type = "80th/50th SES gap")

complete_data_midbottom_80 <-
  pisa_preparer(results_math_midbottom_80, results_read_midbottom_80) %>%
  mutate(type = "50th/20th SES gap")

######

complete_data_topbottom_70 <-
  pisa_preparer(results_math_70, results_read_70) %>%
  mutate(type = "70th/30th SES gap")

complete_data_topmid_70 <-
  pisa_preparer(results_math_topmid_70, results_read_topmid_70) %>%
  mutate(type = "70th/50th SES gap")

complete_data_midbottom_70 <-
  pisa_preparer(results_math_midbottom_70, results_read_midbottom_70) %>%
  mutate(type = "50th/30th SES gap")

#####

complete_gaps <-
  complete_data_topbottom %>%
  bind_rows(complete_data_topbottom_80) %>%
  bind_rows(complete_data_topbottom_70)

complete_gaps %>%
  mutate(country = factor(country, levels = ordered_cnt, ordered = TRUE)) %>%
  filter(type_test == "math",
         country %in% countries) %>%
  ggplot(aes(as.character(wave), difference, colour = type, linetype = type, group = type)) +
  geom_line(stat = "smooth", method = "lm", size = 0.7) +
  facet_wrap(~ country, ncol = 5) +
  scale_colour_discrete(name = "Type of gaps") +
  scale_linetype_discrete(name = "Type of gaps") +
  scale_y_continuous(name = "Gaps in SD", expand = c(0, 0), lim = c(0, 3)) +
  scale_x_discrete(name = NULL, breaks = c(2000, 2009, 2015)) +
  ggthemes::theme_few() +
  theme(panel.spacing = unit(1, "lines"),
        panel.grid.major.y = element_line(colour = "grey"),
        legend.position = "bottom") +
  ggtitle("Evolution of the different achievement gaps")
@
\caption{Evolution of the achievement gap for several gaps}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
<<percentage_change_8020,  include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
perc_increase_fun(complete_data_topbottom_80) %>%
  perc_graph("math",
             "80/20 achievement gap",
             "Percentage change from 2000 to 2015")
@
\caption{Percentage change in the 80/20 achievement gap from 2000 to 2015}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
<<percentage_change_7030,  include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
perc_increase_fun(complete_data_topbottom_70) %>%
  perc_graph("math",
             "70/30 achievement gap",
             "Percentage change from 2000 to 2015")
@
\caption{Percentage change in the 70/30 achievement gap from 2000 to 2015}
\end{center}
\end{figure}

<<eval = F>>=

# 2000
# SC03Q01 School public/private
# 1 Public
# 2 Private
# 7 N/A
# 8 M/R
# 9 Mis

# 2003
# SC03Q01 (8) Public or private
# 1 Public
# 2 Private
# 7 N/A
# 8 Invalid
# 9 Miss

# 2006
# SC02Q01 (8) Public or private
#  1 Public
#  2 Private
#  7 N/A
#  8 Invalid
#  9 Missing 

# 2009
# SC02Q01
# 1 public
# 2 private

# 2012
# SC01Q01 Public or private Num
# 1 Public
# 2 Private
# 7 N/A
# 8 Invalid
# 9 Missing

# 2015
# SC013Q01TA
# 1 Public
# 2 Private
# 7 N/A
# 8 Invalid
# 9 Missing
library(readxl)

tracking_data <-
  read_xlsx("./paper/data/tracking.xlsx", sheet = "all_data") %>%
  map_if(is_double, round, 2) %>%
  as_tibble

library(inequalityintsvy)

central_examination <-
  tribble(
  ~ country, ~central_examination,
  "Australia", 1, 
  "Austria", 0, 
  "Belgium", 0,
  "Bulgaria", 1,
  "Canada", rbinom(1, 1, prob = 0.51),
  "Czech Republic", 1,
  "Denmark", 1,
  "Finland", 1,
  "France", 1,
  "Germany", 0,
  "United Kingdom", 1,
  "Greece", 0,
  "Hong Kong", 1,
  "Hungary", 1,
  "Iceland", 1,
  "Ireland", 1,
  "Israel", 1,
  "Italy", 1,
  "Japan", 1,
  "Korea", 1,
  "Latvia", 1,
  "Liechtenstein", 1,
  "Luxembourg", 1,
  "Netherlands", 1,
  "New Zealand", 1,
  "Norway", 1,
  "Poland", 1,
  "Portugal", 0,
  "Russia", 1,
  "Slovakia", 1,
  "Slovenia", 1,
  "Spain", 0,
  "Sweden", 0,
  "Switzerland", 0,
  "Turkey", 1,
  "United States", 1
  )

# The tracking variables explain very nicely the difference in test scores
# for all countries pooled, up to 50% R squared.


dif_data <- function(my_data, tracking, central, which_gap = "90th/10th SES gap") {
  my_data %>%
    filter(type_test == "math", type == which_gap) %>%
    select(wave, country, difference) %>%
    rename(year = wave) %>%
    mutate(year = as.character(year)) %>%
    left_join(tracking_data, by = c("country" = "cntry_name")) %>%
    left_join(central_examination) %>%
    mutate(num_tracks = ifelse(tracks15y == 1, 1, 0) %>% as.factor,
           age_selection = selage) %>%
    filter(!is.na(num_tracks), !is.na(age_selection), !is.na(difference))

}

ready_data <- dif_data(complete_gaps, tracking_data, central_examination)

ready_data_age <-
  dif_data(complete_gaps, tracking_data, central_examination) %>%
  mutate(age_selection = ifelse(selage >= 15, 1, 0) %>% as.factor)

gaps <- c("90th/10th SES gap", "80th/20th SES gap", "70th/30th SES gap")

all_gaps_models <-
  map(gaps, function(gap) {
    ready_data_age <-
      dif_data(complete_gaps, tracking_data, central_examination, which_gap = gap) %>%
      mutate(age_selection = ifelse(selage >= 15, 1, 0) %>% as.factor)
    
    mod_tracking <-
      brms::brm(
        difference ~
          ztrack +
          zvoc +
          ztrack:zvoc, family = gaussian(),
      data = ready_data_age,
      warmup = 1000, iter = 2000, chains = 5
      )
    
    mod_tracking
})

model_data_merged <-
  map(all_gaps_models, ~ fixef(.x)[, c(1, 3, 4)] %>% as_tibble) %>%
  setNames(gaps) %>%
  enframe() %>%
  unnest(value) %>%
  mutate_if(is_double, round, 2) %>%
  transmute(model = name,
           terms = all_gaps_models[[1]] %>% fixef %>% row.names %>% rep(3),
           estimate = Estimate,
           lower = `2.5%ile`,
           upper = `97.5%ile`)

model_data_merged %>%
  ggplot(aes(terms, estimate, colour = model)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) +
  geom_point() +
  geom_hline(yintercept = 0) +
  scale_colour_discrete(name = NULL) +
  scale_y_continuous(limits = c(-0.5, 2)) +
  ggtitle("Coef from linear model of inequality on degree of tracking and vocational tracking") +
  coord_flip()


library(brms)
# It under predicts the y value rather than over predict
# It has problems predicting the central tendency of the model
# This linear model explains the pooled 90/10 differences

mod_tracking <-
  brms::brm(
    difference ~
      ztrack +
      zvoc +
      ztrack:zvoc, family = gaussian(),
  data = ready_data_age,
  warmup = 1000, iter = 2000, chains = 5
  )

bayes_R2(mod_tracking)

plot_interaction <-
  marginal_effects(mod_tracking,
                 effects = "ztrack:zvoc",
                 int_conditions = list(zvoc = quantile))

pp_check(mod_tracking, type = "dens_overlay", nsamples = 100)
pp_check(mod_tracking, type = "scatter_avg", nsamples = 100)
pp_check(mod_tracking, type = "boxplot", nsamples = 20)
pp_check(mod_tracking, type = "error_hist", nsamples = 6)
pp_check(mod_tracking, type = "ecdf_overlay")

pp_check(mod_tracking, type = "error_scatter_avg_vs_x", x = "zvoc")
pp_check(mod_tracking, type = "error_scatter_avg_vs_x", x = "ztrack")


# I don't know how to estimate VIF's with bayesian reasoning
model_formula <- difference ~ num_tracks + age_selection + zvoc + I(length > 0)
mod_tracking_ext <-
  brms::brm(model_formula, family = gaussian(),
  data = ready_data_age,
  warmup = 1000, iter = 2000, chains = 5
  )

bayes_R2(mod_tracking_ext)

# This is the closest I could get to getting vif's:
lm(model_formula, data = ready_data_age) %>%
  vif()

new_data <-
  ready_data_age %>%
  with(crossing(country = countries,
                num_tracks = unique(num_tracks),
                age_selection = unique(age_selection),
                zvoc = mean(zvoc, na.rm = TRUE),
                length = typical(length > 0)))

predictions <- posterior_predict(mod_tracking_ext, newdata = new_data)
sd_obs <- colSds(predictions)

new_data <-
  new_data %>%
  mutate(
    pred = colMeans(predictions),
    pred_low = pred - (2 * sd_obs),
    pred_high = pred + (2 * sd_obs)
  )

sum_ready_data <-
  ready_data_age %>%
  group_by(country, num_tracks, age_selection) %>%
  summarize(avg_diff = mean(difference),
            diff_low = avg_diff - 2 * sd(difference),
            diff_high = avg_diff + 2 * sd(difference)) %>%
  ungroup()

new_data %>%
  left_join(sum_ready_data) %>%
  ggplot(aes(num_tracks %>% as.factor, avg_diff, fill = num_tracks)) +
  geom_errorbar(aes(ymin = diff_low, ymax = diff_high), width = 0.2, colour = "red") +
  geom_point(colour = "red") +
  scale_y_continuous(limits = c(0, 4)) +
  geom_col(aes(y = pred, alpha = 0.4)) +
  geom_errorbar(aes(ymin = pred_low, ymax = pred_high), width = 0.2) +
  facet_wrap(country ~ age_selection) +
  scale_fill_wsj()
@

<<>>=

# One idea I had was to make a cumulative sum of the trend,
# so the cumulative inequality over time for each country
# and see how each tracking feature explains this cumulative
# pattern, and it does so very well, with each one
# separately (because I have only 30 observations) explaining
# about 22% each. Age selection, up to 30% alone.

vars_unique <- c("length", "num_tracks", "age_selection", "central_examination", "ztrack",
                 "zvoc")

ready_data_two <-
  ready_data %>%
  group_by(country) %>%
  summarize_at(vars(vars_unique), unique) %>%
  mutate(cum_diff = ready_data %>% group_by(country) %>% summarize(m = sum(difference)) %>% pull(m))

mod_tracking <-
  ready_data_two %>%
  lm(cum_diff ~ ztrack + zvoc, data = .) %>%
  arm::display(detail = T)

mod_tracking <-
  ready_data_two %>%
  filter(!is.na(age_selection)) %>%
  brm(
    cum_diff ~ I(age_selection >= 15),
    family = gaussian(),
    data = .,
    warmup = 1000, iter = 2000, chains = 5
  )

bayes_R2(mod_tracking)

pp_check(mod_tracking, type = "dens_overlay", nsamples = 100)
pp_check(mod_tracking, type = "ecdf_overlay", nsamples = 10)
pp_check(mod_tracking, type = "boxplot", nsamples = 30)
pp_check(mod_tracking, type = "stat", nsamples = 200) # very nice to compare central tendency
pp_check(mod_tracking, type = "error_scatter_avg", nsamples = 1000)

pp_check(mod_tracking, type = "loo_pit")
# over prediction
# central tendency is not captured very well
# more under-prediction than over prediction

# update all of this for the previous model!
# y_rep <- posterior_predict(mod_tracking)
# 
# replication <-
#   map(1:2000, ~ {
#   ready_data_two %>%
#   mutate(pred_sample = y_rep[sample(1:4000, 1), , drop = TRUE]) %>%
#   summarize(perc_sample = mean(pred_sample > cum_diff),
#             minus_sample = mean(pred_sample - cum_diff))
# })
# 
# y_pred_data <-
#   replication %>%
#   enframe() %>%
#   unnest()
# 
# y_pred_data %>% qplot(perc_sample, data = ., geom = "histogram", bins = 50)
# 
# y_pred_data %>% {quantile(.$perc_sample)}
# 
# y_pred_data %>%
#   summarize(mean_perc = mean(perc_sample < 0.5))

# Too few data points to predict integers, the distribution is full of empty spaces
# The predictions are too wide! Only 41% of the predictions are between 0.45 and 0.55
# accuracy. There's more underprediction than over prediction

m_data <-
  ready_data_two %>%
  filter(!is.na(age_selection)) %>%
  mutate(pred_median = posterior_predict(mod_tracking) %>% colMeans(),
         ratio_pred = pred_median/cum_diff) %>%
  select(country, ratio_pred, cum_diff, pred_median)

m_data %>%
  ggplot(aes(ratio_pred)) +
  geom_histogram(bins = 50)

m_data %>%
  ggplot(aes(reorder(country, -ratio_pred), 1 - ratio_pred)) +
  geom_col() +
  scale_y_continuous(breaks = seq(-0.3, 0.3, 0.5), limits = c(-0.3, 0.3)) +
  coord_flip()

# Greece, France would have a decrease of about 20-25% of their cumulative
# inequality when adjusting for the age of selection.

# There is both under and over prediction but the over predictions are very extreme

# See how these models explain for the 90/80/70 gaps.
@

<<next_steps>>=
# Next steps:

# Continue by doing the multilevel models to see what explains what. Include
# all indicators from the reardon/russian girl paper.
  
# Graph the increase in each country vs the increase/decrease of the economic inequality indicators
# Specially the 90/10

# Calculate how big is the gap between reading and math
  
# Continue with the PIRLS to see if there are specific patterns in 4th and 8th graders gap.
  
# Get each country trendline adjusted for the inequality indicators and place in the same country graph.

# Should I add the parent's education in the lm model to see how trends change adjusted for that?

# A weak welfare system, together with income inequality, what's their pattern?
# What if we put the school differentiation/tracking aspect in? Are there country groups based on these
# patterns.

# In countries where there is high differentiation/tracking, is there a jump in the evolution of the gap between PIRLS/TIMSS and PISA?
@


\end{document}