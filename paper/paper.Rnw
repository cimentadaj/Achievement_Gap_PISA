\documentclass[11pt, a4paper]{article}
\bibliographystyle{apalike}
\pagestyle{headings}

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
\usepackage{pdflscape}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage[round, colon]{natbib}
\usepackage[colorlinks]{hyperref}
\AtBeginDocument{%
  \hypersetup{
    citecolor=blue,
    linkcolor=blue,   
    urlcolor=blue}}

\title{First paper - Draft}
\author{Jorge Cimentada}


\begin{document}
\setlength{\parindent}{2em}
\setlength{\parskip}{1em}
\showboxdepth=5
\showboxbreadth=5

\maketitle

<<working directory, echo = F>>=
options(scipen = 213141)
opts_chunk$set(echo = F,
               message = F,
               warning = F,
               include = F,
               cache.lazy = F,
               results = 'asis')
@

<<default_conf>>=
  library(knitr)
  library(arm)
  library(saves)
  library(haven)
  library(PISA2000lite)
  library(PISA2003lite)
  library(PISA2006lite)
  library(PISA2009lite)
  library(PISA2012lite)
  library(intsvy)
  library(cimentadaj) # # devtools::install_github("cimentadaj/cimentadaj")
  library(countrycode) # For region variable
  library(car)
  library(readr)
  library(SAScii)
  library(inequalityintsvy) # devtools::install_github("cimentadaj/inequalityintsvy")
  library(lme4)
  library(modelr)
  library(tidyverse)
  library(ggrepel)
  
  # source("./transform_data.R")

  # Conf for PISA_2015
  pisa2015_conf <- list(variables = list(pvlabelpref = "PV",
                                         pvlabelsuff = "READ",
                                         weightFinal = "W_FSTUWT",
                                         weightBRR = "W_FSTURWT"),
          parameters = list(cutoffs = c(357.77, 420.07, 482.38, 544.68, 606.99, 669.30),
                                          percentiles = c(5, 10, 25, 75, 90, 95),
                                          PVreps = 10,
                                          BRRreps = 80,
                                          weights = "BRR",
                                          replication_scheme = 'pisa')
  )
  
  countries <- c("Finland",
                 "France",
                 "New Zealand",
                 "Austria",
                 "Australia",
                 "Sweden",
                 "Czech Republic",
                 "Canada",
                 "Hungary",
                 "Iceland", "Netherlands",
                 "Spain",
                 "Belgium",
                 "Italy", "Norway",
                 "United Kingdom",
                 "Greece",
                 "Denmark",
                 "Israel",
                 "Poland",
                 "United States",
                 "Germany",
                 "Turkey",
                 "Russia")
@

\tableofcontents

<<loading_data-recoding>>=
pisa_all <- read_rds("./data/pisa_listcol.Rdata")
pisa_all2 <- pisa_all

years <- seq(2000, 2015, 3)
  
db <- paste0("pisa", years)
pisa_all2$value <- map2(pisa_all2$value, db, ~ { .x$wave <- .y; .x})
pisa_all2$value[[1]]$CNT <- pisa_all2$value[[1]]$COUNTRY
  
pisa_all2$value <- map(pisa_all2$value, ~ {
  
# 2000 to 2015
# The coding is from 0 to 6, where 0 is no schooling and 6 is
# BA or above.

# When turning 0:6 to numeric, it becomes 1:7 that's why
# I recode 8:9 to NA. This, however, didn't work for last two surveys
  
  .x$father_edu <- car::recode(as.numeric(.x$FISCED), "8:9 = NA")
  .x$mother_edu <- car::recode(as.numeric(.x$MISCED), "8:9 = NA")
  .x$high_edu_broad <- pmax(.x$father_edu, .x$mother_edu)
  .x$country <- pisa_countrynames[as.character(.x$CNT)]
  
  if (any(unique(.x$wave) %in% c("pisa2012", "pisa2015"))) {
    # These two surveys were from 0:6 so I had to add + 1
    # so that it equals 1:7 as all other surveys.
    .x$father_edu <- .x$father_edu + 1
    .x$mother_edu <- .x$mother_edu + 1
    .x$high_edu_broad <- .x$high_edu_broad + 1
  }
  .x
})
  
reliability_pisa <-
  c("2000" = 0.81,
    "2003" = 0.85,
    "2006" = 0.78,
    "2009" = 0.74,
    "2012" = 0.82,
    "2015" = 0.74) # 2015 imputed

@

<<escs_trend, cache = TRUE>>=
  # Rescaled trend ESCS data to merge.
  # This only has data for seq(2000, 2012, 3) because
  # PISA 2015 has the ESCS trend variable.
  dir <- tempdir()
  file_name <- "escs_trend.zip"
  download.file("http://vs-web-fs-1.oecd.org/pisa/trend_escs_SPSS.zip",
                destfile = file.path(dir, file_name))
  unzip(file.path(dir, file_name), exdir = dir)
  escs_trend <- map(file.path(dir, list.files(dir, pattern = ".sav")), haven::read_spss)
  file.remove(file.path(dir, list.files(dir)))
  
  escs_trend <-
    map(escs_trend, ~ {
    mutate(.x, cnt = pisa_countrynames[cnt]) %>%
    rename(country = cnt)
  })
@

<<merge_escs_pisa, cache = TRUE>>=
   # Next we'll merge the ESCS data with the PISA data. As explained above, the 6th data (PISA
  # 2015) doesn't need to be merged so I exclude it with this vector
  exclude <- -6
  
  # Loop in parallel to the PISA data, the ESCS data and the year vector (which is seq(2012, 2015, 3))
  pisa_all2$value[exclude] <-
    pmap(list(pisa_all2$value[exclude], escs_trend, years[exclude]), function(.x, .y, .z) {
    
    # The escs data needs to have the key variables the same class as the
    # same data.
    escs <-
      .y %>% mutate(schoolid = as.numeric(schoolid),
                    stidstd = as.numeric(stidstd))
    
    # .z is the corresponding year that will be created as a column
    # And perform the same transformation of the key variables as in the ESCS data
    data_trend <-
      .x %>%
        mutate(
          year = .z,
          schoolid = as.numeric(as.character(SCHOOLID)),
          stidstd = as.numeric(as.character(STIDSTD))
          ) %>%
   left_join(escs,
              by = c("country", "schoolid", "stidstd"))
    
    message(paste(unique(.x$wave), "done"))
    
    data_trend
  })
  
  pisa_all2$value[[6]] <-
    pisa_all2$value[[6]] %>%
    rename(escs_trend = ESCS)
@

<<functions_for_modelling>>=

# Function calculates the bottom 30th quantile for the bottom educated and the 70th quantile
# for the top educated. If the quantiles can't be estimated, it returns two NA's instead
quantile_missing <- function(df, weights, probs) {
    
    quan <- try(Hmisc::wtd.quantile(
      df$escs_trend,
      weights = df[[weights]],
      probs = probs
      ))

    if (any("try-error" %in% class(quan))) {
      return(c(NA, NA))
      } else {
     return(c(quan[1], quan[2]))
    }
}
  
# Producing the plot to get the difference between the top 30% of the high educated
# vs the bottom 30% of the low educated. This function loops through each dataset/country
# and survey reliability and estimates the difference while also extracting the s.e. of each
# difference.
  
# It returns a dataframe for each survey with all countries and respective coefficients and
# standard errors.
test_diff <- function(df, reliability, test, probs) {
  
    map2(df, reliability, function(.x, .y) {
      
      conf <- if (unique(.x$wave) == "pisa2015") pisa2015_conf else pisa_conf
      weights_var <- conf$variables$weightFinal

      country_split <- split(.x, .x$country)
      
      country_list <- map(country_split, function(country) {
        print(unique(country$country))
        
        quan <- quantile_missing(country, weights_var, probs)
        
        # It's very important to create a variable that returns the number of observations of this dummy
        # For each country. Possibly to weight by the number of observations.
        country$escs_dummy <-
          with(country, case_when(escs_trend >= quan[2] ~ 1,
                                  escs_trend <= quan[1] ~ 0))
        country
      })
      
      .x <-
        enframe(country_list) %>%
        unnest(value)

      .x <-
        .x %>%
        dplyr::select(wave,
                      matches(paste0("^PV.*", test, "$")),
                      escs_dummy,
                      country,
                      one_of(weights_var),
                      AGE)
      
      message(paste(unique(.x$wave), "data ready"))


      test_vars <- paste0("PV", seq_len(conf$parameters$PVreps), test)
      .x[test_vars] <- map(.x[test_vars], ~ ifelse(.x == 9997, NA, .x))
      
      # Calculate median math score of all PV's
      .x$dv <- apply(.x[test_vars], 1, median, na.rm = T)
      
      # Should I estimate the model separately by country?
      mod1 <- lm(dv ~ AGE,
                 weights = .x[[weights_var]],
                 data = .x,
                 na.action = "na.exclude")
      
      # Take residuals of model and divide by rmse. Multiply that by
      # 1 / sqrt(reliability of each survey), which is .y in the loop.
      .x$adj_pvnum <- resid(mod1)/rmse(mod1, .x) * 1 / sqrt(.y)
      
      mod2 <-
        lmer(adj_pvnum ~ escs_dummy + (1 + escs_dummy | country),
             data = .x,
             weights = .x[[weights_var]])
      
      # Take the country coefficients (absolute coefficients)
      country_coef <-
        coef(mod2)$country %>%
        rownames_to_column() %>%
        gather(escs_dummy, Mean, -rowname) %>%
        mutate(escs_dummy = dplyr::recode(escs_dummy,
                                          `(Intercept)` = "0",
                                          `escs_dummy` = "1"))
      
      # Take the absolute country standard errors
      se <-
        se.coef(mod2)$country %>%
        as.data.frame() %>%
        rownames_to_column() %>%
        gather(escs_dummy, s.e., -rowname) %>%
        mutate(escs_dummy = dplyr::recode(escs_dummy,
                                          `(Intercept)` = "0",
                                          `escs_dummy` = "1"))
      
      results <-
        inner_join(country_coef, se, by = c("rowname", "escs_dummy")) %>%
        rename(country = rowname) %>%
        arrange(country, escs_dummy)
      
      message(paste0(unique(.x$wave), " modeling done"))
      results
    })
}


# Adapted from: https://github.com/jtleek/slipper/blob/master/R/slipper.R
# Returns a tibble with the actual expr + the bootstrapped expr.
bootstrapper <- function(df, expr, B = 100, n = nrow(df), replacement = TRUE) {
  bootstrapper_(df, lazyeval::lazy(expr), B, n, replacement)
}

bootstrapper_ <- function(df, expr, B = 500, n = nrow(df), replacement = TRUE) {
  obs_val = lazyeval::lazy_eval(expr, data = df)
  boot_val = replicate(B, {
    newdata = sample_n(df, n, replace = replacement)
    lazyeval::lazy_eval(expr, data = newdata)
  })
  out = tibble(type = c("observed", "bootstrap"), 
               value = c(obs_val, mean(boot_val, na.rm = T)))
  return(out)
}

# For example
# bootstrapper(mtcars, mean(mpg), B = 200)
@

% This chunk needs to have cache = TRUE once you want to run it for like 2 hours until 
% the results_* models have been created once and the cache can save them

<<modeling, cache = TRUE>>=
adapted_year_data <-
    map(pisa_all2$value, ~ {
      if (unique(.x$wave) == "pisa2000") {
        # pisa2000 has a different coding so here I recode 6 to 7 so that in all waves the top edu
        # is 7 and the bottom is 1
        .x <-
          mutate(.x, new_hisced = as.character(dplyr::recode(as.numeric(high_edu_broad), `6` = 7)))
      } else {
        .x <-
          mutate(.x, new_hisced = as.character(high_edu_broad))
      }
      .x
})

# results_math <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.1, 0.9))
# results_read <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.1, 0.9))
# results_math_topmid <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.5, 0.9))
# results_read_topmid <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.5, 0.9))
# results_math_midbottom <- test_diff(adapted_year_data, reliability_pisa, "MATH", c(0.1, 0.5))
# results_read_midbottom <- test_diff(adapted_year_data, reliability_pisa, "READ", c(0.1, 0.5))

results_math <- read_rds("./data/delete.Rdata")
results_read <- read_rds("./data/delete_read.Rdata")
results_math_topmid <- read_rds("./data/delete_math_topmid.Rdata")
results_read_topmid <- read_rds("./data/delete_read_topmid.Rdata")
results_math_midbottom <- read_rds("./data/delete_math_midbottom.Rdata")
results_read_midbottom <- read_rds("./data/delete_read_midbottom.Rdata")
# US is missing for reading

# Cache is not working properly for the code above, so I just load the saved cached file
# load("./paper/cache/modeling_9a0b38d1d53fa243b0242580f0672fa5.RData")
@

\section{Introduction}

\section{Literature Review}
% You have a bunch of citations to take from here
Educational inequality and its long term impacts is a topic that has been prominent in the social science literature for the past 30 years. Are we destined to belong to the same social status as our parents? Is meritocracy over, if it ever existed? These questions have motivated, in conservative terms, much of the research on social mobility and social inequalities, for a good part of the 20th century and 21st century. When James Colem(1966) released his famous Coleman report it raised the topic to starlight by suggesting that family SES and student performance are tightly linked. Fast-forward today, we've understood the relationship much better, although far from being clear. The work of James Heckman, for example, has clearly showed that cognitive and non-cognitive inequalities are present before entering school (cite heckman). Moreover, these inequalities can be narrowed significantly if the children coming from unfavourable conditions are exposed to high quality learning environments. One particular finding coming from (cite heckman skill begets skill) is that the cognitive level of a child in time \(t\) is a direct function of the experiencies from time \(t-1\). Although this sounds logical, it is often not acknowledged properly.

The implications of this cummulative model suggests that it is much less cost-effective to invest in children in time \(t\) that in \(t-1\). That is why the whole debate about narrowing inequality between polarized families should start in early education -- it is the cheaper than investing in later education and it brings about the largest returns. Despite all of these findings and investments to reduce the gaps, we still find that the relationship between parental education or socio-economic status, is present in virtually all empirical studies of social mobility and inequalities (cite breen and goldthorpe, cite waldfogel what children need, cite bradbury 2015, cite chetty for recent evidence). What we don't know is how and why this relationship is formed from such an early age. Moreover, many have suggested different explanations and the topic has been very contested (duncan and brooks-gun 1997).

Social mobility has deepend our knowledge on the odds and relationship between intergenerational transmission of SES. The field of economics of education has also helped to understand that education is by far the investment that yields the best outcomes not only for the child and his/her family, but to the economy as a whole, as it boosts economic activity, it helps the labour market to improve job conditions and maintain a rapid economic growth (cite hanushk and woesmann study). We've become so intertwined with the subject that we've virtually spent most of our time studying the mechanisms through which this inequality comes about. Naturally, we want to do that to be able to reverse it and help disadvantaged children reach their fullest potential. Despite our good intentions, we've concentrated little on the magnitud of the gaps, specially in terms of cognitive abilities. In addition, since most research has concentrated on the American case, we haven't been able to learn which countries have the biggest or smallests gaps, and whether they've been narrowing or closing over time.

Virtually in all countries, be it developed or developing, there is inequality of opportunity. But there is considerable variation in the magnitud of this effect. For example, the Scandinavian countries, particularly Denmark and Sweden, prove to be very mobile countries \citep{esping2012, breen2007, shavit1993}.

Taking the Danish example, we learned a great deal about how to improve social mobility by first learning that Denmark is by far one of the most mobile countries, boosting the chances of upward mobility for less advantaged children (Bjorklund and Jantti, 2009; Jaeger and Holm, 2007). But the important finding came when we discovered the main reason behind their social elevator: its' educational system. For example, research by Esping and Waldfogel and Gosta's phd student on Denmark, show that the Danish early education system is particularly efficient at giving free high quality education, regardless of socio-economic status. Moreover, it tracks students into different curricula very late compared to other Europen countries Europe (age 16). The importance of this finding, is that we should step back and first study whether the effect is there, how big is it, and then proceed to find the causes behind it.

Recent research on educational inequality has found that achievement gap in cognitive abilities between High-SES and Low-SES kids has been widening over the years. Literature on the topic has mainly concentrated on studying the American case \citep{reardon2011} but other international evidence is emerging with a very similar landscape. The United States is usually the case of study because it is the only country where cognitive testing is present as early as 1940. This trend has allowed researchers to study achievement gaps in a lengthy period of time. In fact, using this information, \citep{reardon2011} is the first to investigate the evolution of the cognitive gap and the results are very surprising. Not only has the cognitive gap between the 90th income percentile and the 10th income percentile grown over time, but it has grown faster and to be wider than the highly contested white-black gap (cite study of white-black gap -waldfogel study). Surprisingly, the gaps have reversed and now a days we find that the income achievement gap is nearly twice as large as the black-white achievement gap. The widening of the achievement gap has been happening in parallel to the growth of income inequality, although very suggestive, it is hard to link both things causally. However, a recent \href{http://www.epi.org/files/pdf/101972.pdf}{report} by the Economic Policy Institute finds that the black-white income gap has been growing since 1979. If income inequality would be a strong a direct function of the achievement gap, we should expect for the white-black achievement gap to be widening rather than narrowing, as it is now (Magnuson and Waldfogel 2008) \footnote{The black-white achievement gap narrowed significantly for cohorts betwen 1950 and 1970.}.

\citet{reardon2011} finds that the increase has occured predominantely from the 1970's until the 2000's. In fact, the hard numbers suggest that the gap widened by ~ 40-50\%. The author also estimates the rate of change using data from the 1940's and finds an even higher increase of ~ 75\%. Given that the studies before 1970 are less reliablle in terms of comparability and sampling design, the author computes all results for both before/after 1970. To provide a definitive answer to the size of the gap, \citet{reardon2011} concludes that the U.S gap between the 90th and 10th income percentile is at about 1.25 standard deviations in the year 2010. Using longitudinal data, \citet{bradbury2015} find similar results. Their empirical analysis suggests that for American 14 year olds, the gap is above 1 standard deviation but lower than 1.25. Surprisingly, \citet{duncan2011} find similarly to the previous studies and confirm a gap of ~ 1.25/1.50 standard deviations. \footnote{One important drawback of these studies is that they don't present the uncertainty of this estimates. Not necessarily to gauge their statistical significance, but to simply asses how much we can trust their accuracy. It could be that the gap is at ~ 1.25 standard deviations, varying up to 1.75 and down to 0.80. Right now we don't know the upper/lower bound of this estimate, making it difficult to compare when new evidence arises.}

In a follow-up study, \citet{reardon_portilla} unexpectedly uncovered a new finding: the reversal of the trend. This follow-up study concentrated solely on the Kindergarten gap in which they took a snapshot of the achievement gap in Kindergarten in 1998, 2006 and 2010 and found that the 90th/10th income gap in readiness closed modestly. Furthermore, using data from fall and spring in the same kindergarden year, it seems like the gap in narrowed at a rate of 0.01 and 0.008 standard deviations per year for mathematics and literacy between 1998 and 2010. In contrast to \citep{reardon2011}, we find that in a 30-year span the gap was systematicaly increasing at a rate of 0.02, something reasonably close to the previous estimates. Their results not only hold for the income achievement gap, but they also recorded a particular decline in the white-hispanic gap.

The American situation is a very distinctive one relative to Europe. The reasons the authors find a reversal in the trend could be numerous and should be studied very close. For example, the American educational system lacks any formal curricular differentiation \emph{à la} European style. It is true nonetheless that \citet{reardon2011} did not cover from the period 2000 onwards, which is specifically the trend they studied. In contrast, \citet{reardon2011} suggests that the reversal is likely due to the high increase of preschool enrollment. They suggest similarly that in this same period (1998 - 2010) the income achievement gap in early schooling enrollment decreased substantially. This explanation still needs further confirmation.

Motivated by these recent results, some authors have taken this analysis to an international context in order to discover between-country trends. The unique work of \citet{bradbury2015} employs a unique comparative analysis of Australia, United Kingdom, United States and Canada. Their research design is very distinctive in that they use longitudinal data from children as early as age 2 and study the evolution of the achievement gap up until age 14 \footnote{To the best of my knowledge this is not only the first study that uses panel data to study achievement gaps, but to also do it between countries}. The core finding behind the book is that the American achievement gap is much wider than in any other comparison country, specially Australia and Canada. They find that once the achievement gap is present in early school entry, it doesn't seem to narrow or neither widen very much over the life course. In fact, they calculate that the schooling environment once they enter school can only explain about ~ 30\%-40\% of the high school SES gap. This suggests that once the achievement gap widens before entering school, it carries a social-scar effect \footnote{However, schooling could be preventing the gap to widen even more, and very rigorous RCT's show that high quality schooling can indeed help ease the gap, in some instances even close it.}. Once exception is the United Kingdom, which they find closed the gap in early primary years. This can likely be due to the comprehensive schooling and also the public support by the welfare state in dimensions like health.

One limitation of their study is that they concentrate on countries which have a very particular educational structure, namely the fact that there is little formal stratification in terms of curricula. These four countries have no major jump in school selection, quite the opposite to the average European country. A thorough review by \citet{werfhorst_mijs} sheds some light on the subject. First and foremost, they gather substantive evidence showing that countries which have a highly tracked curriculum tend to have high levels of inequality, measured in terms of achievement gaps. \citet{hanushek_woesmann_tracking}, use the Progress in International Reading Literacy Study (PIRLS), the Trends in International Mathematics and Science Study (TIMSS) and the Programme for International Student Assessment (PISA) surveys to gauge whether highly tracked countries do indeed increase inequality after students pass the age at first selection of tracking. The results suggest that early tracking increases educational inequality. While less clear, there is also a tendency for early tracking to reduce mean performance. Moreover, \citet{micklewright} using similar data but a different empirical strategy, finds that countries which have a high level of tracking, are distinctively unequal in the difference between the top 95th and bottom 5th performers. In fact, the difference in test scores between these two groups is about 10 times higher then the average annual gain of a year of schooling.

Another limitation of their study is that their analysis is based on four surveys that have significant differences in terms of questions, sampling and populations and cannot be easily compared. Their findings are very reliable but should be taken as suggestive at best.  For this reason we should also pay particular attention to studies such as \citet{anna2016} and \citep{anna2016_global} which have attempted not only to compare gaps between countries, but to evaluate whether there is a general increase in educational inequality in many countries using much more comparable studies. These studies tackle a completely different question from the above, namely to use study cross-sectional differences between many countries, instead of over-time analysis of student gaps. However, they do provide support for the overall finding that the achievement gap is certainly not narrowing over time.

\citet{anna2016}, again using PIRLS, TIMSS and PISA, assess whether there are patterns of cross-national variation in the achievement gap. In other words, does the achievement gap differ between countries? Their work suggests that there is considerable variation in the achievement gap between top and bottom earning families across many developed countries. In comparison to the literature on achievement gaps, they find that the U.S has a gap of ~ 1.20 SD in 2001 which increase to around ~ 1.30 in the year 2006 while Germany has a decreasing gap from around ~ 1.25 to ~ 1 standard deviation in the same year-span. However, these numbers vary a lot and carry a great deal of overlapping uncertainty.

They go even further and link this achievement gap to several country-level indicators related to income inequality, school differentiation, central exams, among other things. The correlations are very suggestive  as explanatory mechanisms but they are very cautios in drawing causality, specially because they are all reasonably correlated. However, one interesting question is whether these country gaps have evolved over time. With their data, they only have 3 countries which are present in all waves but they also have very few waves because their question of interest (income categories) was only asked in three waves. That is why their study is more about between country gaps rather than the magnitude and evolution of the gaps.

\citet{anna2016_global}, building on the work of \citet{anna2016} and \citet{reardon_portilla} pooled together all the previously mentioned data, together with over 10 more studies ranging from the year 1964 until 2015 in order to discover differences between and across countries. With over 50 years of data, and over 100 countries, she finds that there seems to be a general pattern of increasing achievement gap. However, once she disentangles the relationship by country, she finds a sizable amount of heterogeneity, with some countries seeing the achievement gap narrowing, others no change at all, while others record a steady increase. This is revealing because it doesn't really pay off to look at general average once each country has their own distinctive gap and evolution. Another important finding is that the achievement gap is clearly no universal and should be studied in context. 

One clear limitation of their study (as well as \citet{reardon2011}) is that the adjust for the age of each child in all studies. Although for their modeling purposes this is the right thing to do \footnote{The differences in achievement could simply be due to changes in cognitive abilities across the lifetime. However, as we've noted before, \citet{bradbury2015} find that the achievement gap is very stable across the life time}, they are masking age-specific achievement gaps by controlling for age, such as \citet{reardon2011} did. We clearly see in \citet{reardon_portilla} that paying attention to age-specific gaps varies reasonably even in short periods of time.

In fact, the evolution of high/low SES gaps for preschool children might be much less marked than the same gap for high school children. The explanation, although very debated, has been gaining much support in recent years. In countries with high levels of curricular differentiation, the transition from early schooling into the tracking system has been found to increase inequality of learning \citep{hanushek_woesmann_tracking}. Moreover, the vast sociological literature on educational transitions systematically finds that tracking tends to foster between-track inequality rather than erode their differences by tackling their specific needs \citep{werfhorst_mijs}. Based on this, we cannot simply assume that the achievement gap has been neither constant across cohorts (because there have been tracking reforms in many countries, introducing as well as elimination tracking structures) nor the same between ages, because tracking/no tracking might exarcebate the achievement gap.

Talk about how the achievement gap has been widening in Malaysia and South Korea (or Japan?)
Is efficiency related to opportunity here? Is efficiency what explains the inequality of opportunity?
Note how many of these studies haven't really concentrated on who is getting better or worse: top or bottom?
Talk more about how countries with high social mobility has been linked to smallest achievement gaps
Talk about Durpiez and Dumay and how there's not relationship between inequality income - inequality achievement in contrast to reardon and anna who find some relationship.

\section{Research questions}

With this being said, this paper introduces one novelty in the literature which is to evaluate the evolution of the high/low SES achievement gap in the past 15 years for all PISA participant countries. This is different from previous work because it concentrates solely on 15 year old children, and it attempts to capture the evolution of the achievement gap for many countries. The advantages of this study are twofold.

First, we concentrate on the evolution of the gap for only 15 year olds, which will serve as a comparison to the single year-country snapshot of \citet{anna2016} and the evolution of the Kindergarten gap in \citet{reardon_portilla}. As we've seen before, there are reasons to think that specific age-groups have seen changes in the achievement gap. Moreover, in almost all countries with a tracked curriculum children are either at or in the process of tracking by the age 15, meaning that we will be able to link whether tracked countries are the most variable in their evolution of achievement gaps.

Second, we will be able, for the first time, to study the evolution of the achievement gap for several countries other than the United States. This will help asses the mangitude of the inequality as well as the rate of growth/decline. Thirdly, this paper not only documents the size and changes of the SES gap, but studies with particular attention the source of the changes. That is, we study whether bottom performers are falling behind, if top performers are gaining advantages, or if both phenomenas are simultaneously at play.

More formally, We're interested in studying
a) The size of the achievement in a comparative perspective and its relationship to overall achievement levels;
b) Which countries are experiencing changes in the achievement gap;
c) the rate at which each country-gap is widening/narrowing and;
d) establishing whether the gaps are widening/narrowing because particular groups are getting ahead/behind.

We develop each question separately for more detail.

a) We want to test the notion that better performing countries have a smaller degree of inequality than other countries. \citep{werfhorst_mijs} emphasize that there is empirical evidence that suggests this. This pattern is not so obvious, however. For example, countries with high leves of tracking could maximize student performance, specially the high SES students, raising their overall performance and thus raising the national performance score. But if the bottom performers are not gaining at the same rate, then the achievement gap will inevitable grow resulting in a high performing countries with a widening achievement gap.

b) The seminal work of \citet{reardon2011} suggests that achievement gaps change, and they do so much quicker that we though. After recording a SES gap increase of about 40\% in only 30 years, \citep{reardon_portilla} stress that they also found a significant decrease in only 15 years of data. This shows that it is important to study the changes in the achievement gap over time. This will bring a useful comparison and pinpoint which countries are doing the best to reduce the gap.

c) We want to compare the percentage change at which the gap widened/narrowed from the first to the last year available. This will give us a general idea of the overall change over time, and will allow us to compare our estimates to the actual literature \footnote{Although no study has performed this age-specific achievement gap for comparable tests over such a long time. Our results will serve as comparison for other studies that use age-specific groups, such as 4th graders.}

d) The widening/narrowing of the achievement gap has a source, which has been often studied to be related to everything from educational spending, income inequality, time allocation to students and preschool enrollment. The literature has concentrated very narrowly on whether the gap is increasing because the top performers are getting ahead, because both are distancing or because the bottom is falling behind. We shall pay particular attention to identifying the rate at which the top/bottom groups are evolving over time. This type of analysis is particularly useful in jotting down the mechanisms through which the gap is evolving. If the bottom performers are stagnated whereas the top is gaining ground, the efficiency-trade off dilemma of tracking might be much more credible than other explanations.

\section{Methods}

\subsection{Data}

<<country_sample_numeric_vec>>=
country_rows <- 
  map_dbl(adapted_year_data, nrow) %>%
  format(big.mark = ",")
@

To investigate the above mentioned questions I will be using the Programme for International Student Assessment (PISA). PISA is a survey carried out every three years that aims to evaluate education systems by testing the skills and knowledge of 15-year-old students. Currrently, PISA has six waves starting which started in 2000 up until 2015, where recently, over half a million students were tested in mathematics, literacy and science in over 70 countries, both developed and developing ones.

PISA collects data through a two-stage stratified sampling design. With the help of official governments, PISA randomly chooses 150 schools in each country, where they then randomly pick thirty 15 year olds to undertake the two hour tests. The sample size for PISA 2000 is \Sexpr{country_rows[1]}, \Sexpr{country_rows[2]} for PISA 2003, \Sexpr{country_rows[3]} for PISA 2006, \Sexpr{country_rows[4]} for PISA 2009, \Sexpr{country_rows[5]} for PISA 2012, and \Sexpr{country_rows[6]} for PISA 2015. Together with the subject tests, PISA collects personal information from students, their families and their school environment (including teacher surveys), that serves as relevent background information that can be matched to the students performance. With the recent inclusion of PISA 2015, these six waves make up a time-series analysis of 15 years, enough to visualize changes in the structure of an educational system. None of the literature cited so far has used the last PISA wave, which was recently released in December 2016.

To identify a family's socio-economic status PISA collects several variables that measure different dimensions. Classically, they ask student's their parent's educational level. Scholars have considered this to be a reliable recall given that we expect fifteen year olds to know their parent's level of education \citep{reardon2011}(cite more here). This question has been asked in every wave and holds a somewhat similar coding across time, although the first two waves have a different coding. In spite of this, another limitation is the fact that parent's education is measured with the ISCED classification, something that has changed over time. For example, until PISA 2009, the preferred framework was ISCED 1997, whereas the next wave switched to the newly developed ISCED 2011 classification. Both these classification schemes have equivalent look-up tables, but this requires a detailed inspection of the codings. Aside from all these limitations, this is very reliable and important variable that measures an important factor of socio-economic status.

Another social background variable PISA collects is the International Socio-Economic Index of Occupational Status (ISEI). This variable captures the economic status of the family, the closest it can without asking for income information.  This index variable was developed by Ganzeboom (cite) and it attempts to measure occupational status using a continuous measure. This indicator has been found to ourperform classical occupational classifications such as the Erikson-Goldthorpe-Portocarero schema (cite). It has been scaled for comparability between waves and some authors have used it for inequality studies finding expected results to be consistent with social origin literature \citep{anna2016_global}. PISA also includes a plethora of indicators on family wealth, home educational resources, the number of books in the home, among many other material resources in the household.

Yet one of the most relevant variables for our study is a composite SES index created by the PISA team. The index of economic, social and cultural status (ESCS) was created on the basis of the following variables: the International Socio-Economic Index of Occupational Status (ISEI), the highest level of education of the student’s parents, the PISA index of family wealth (which measured the material wealth of the family), the PISA index of home educational resources; and the PISA index of possessions related to "classical" culture in the family home (mainly about books in the household) \citep{oecd_glance_2002}. This variable, aside from capturing all relevant dimensions of SES, such as education, occupation, and material resources, takes care of transforming the variables into comparable metrics across waves. To the best of our knowledge, this is the first paper that uses the newly-released ESCS index \citep{pisa_2015_results} which was rescaled so that all ESCS indexes are suitable for over-time analysis \footnote{These rescaled indices can be found in the \href{http://www.oecd.org/pisa/data/2015database/}{PISA website} under \emph{Rescaled Indices for Trend Analyses}.} In other words, the ESCS index does not need any transformation or coding updates because it is ready for comparison over time.

Aside from SES, the other most relevant variables are test scores for Mathematics, Literacy and Science. PISA does not provide a single test result for each respondent. Instead, it provides a \emph{series} of 'plausible values' that the child could actually score. As explained in the PISA manual \citep{pisa2012_technical}, these are imputed values that resemble individual test scores and have approximately the same distribution as the latent trait being measured (the true distribution of the possible scores a student can achieve). Suppose we have \(\mu_i\), the average student test score in Mathematics for student \(i\). Instead of estimating \(\mu_i\) alone, plausible values estimate a distribution of possible \(\mu\text{'s}\) for student \(i\), together with the likelihood of each \(\mu_i\) based on the respondents answers on the test. This is defined as the posterior distributions of \(\mu\text{'s}\) for student \(i\). The reason why we use this procedure is because estimating a single estimate \(\mu_i\) is plagued with measurement error, among other types of bias \citep[see][]{wu2005}. The number of plausible values for PISA waves are usually five (although ten for PISA 2015) random draws from this distribution. In practice each student has 5 scores for each test, that resembles this distribution. They are continuous, ranging from 0 to 500, with a mean of 250.

\subsection{Data analysis}

The aim of this paper is to identify and disaggregate country trends in the achievement gap for several countries. To represent the SES gap, most of the literature on achievement gaps has concentrated on indicators such as parental education, parental occupational status, income achievement gaps and actual SES achievement gaps \citep{fryer2004, hanushek_woesmann_tracking, saw2016, bradbury2015, byun2010}. The actual calculation of the achievement gap varies substantially and different strategies have been implemented. For example, \citet{micklewright} calculates the difference in achievement by crudely subtracting the gap between the 95th and 5th percentile of the mathematics distribution. Although in principle you should be able to capture some type of SES effect like this, theoretically, it should be much more accurate to difference out the mean score of, for example, parental education or some other SES proxy. \citet{saw2016}, for instance, used parental education as a proxy of SES, whereas \citet{byun2010} use a similar SES index as ours, but created by them.

\citet{reardon_portilla, anna2016, anna2016_global} used a different method developed by \citet{reardon2011} which we partially adopt in this paper. SES achievement gaps are measured as the difference in standardized achievement between the 90th and 10th percentiles of the chosen SES variable. The rule of thumb to choose the 90th, 50th and 10th percentile is arbitrary, others have used, for example, the 5th, 50th and 95th \citep{micklewright} while the literature has been following the standard set by \citet{reardon2011} to use 90th/10th percentiles.

For each country in each study, SES disparities in achievement are measured as the gap in standardized achievement between the 90th and 10th percentiles of each country’s distribution of each SES variable, following Reardon’s (2011) method for income achievement gaps.

The original strategy of \citet{reardon2011} is as follows: first, achievement is standardized (see below for a mathematical explanation of the standardization). We then use it to calculate the mean achievement (and standard error) for each category of the SES variable of interest (parent's education, income categories, etc..). "Category means are plotted at their percentile ranks and cubic models are fit through the points using weighted least squares. Finally, achievement at each country’s 90th and 10th SES percentiles is interpolated from the model" \citep{anna2016_global}. The result is a SES gap from an ordinal variable of interest.

As mentioned before, PISA does not provide a single achievement indicator. Instead, we take the median of all plausible values for each student \footnote{Since each plausible value is a random draw from a theoretical latent normal distribution of possible student achievement scores, the median should be precise in getting a central measure of the latent distribution.}, resulting in one single score.

To standardize the test score we fit a linear model

\begin{equation}
Y_i = \alpha + \beta_1 * AGE_i + \epsilon_i, \epsilon_i ~ N(0, \sigma^2)
\end{equation}

for each wave,  where \begin{math}Y_i\end{math} is the median student test score and \begin{math}AGE_i\end{math} is their age measured in months (because all children should be 15 year olds) weighted by the student sample weights.

We then adjust \begin{math} \hat{Y_i} \end{math} by

% I think the denominator could be wrong! Because I include y_hat and that's what the equation is estimating
\begin{equation}
\hat{Y_i} = \frac{\hat{\epsilon_i}}{\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2}}
\end{equation}

% # Take residuals of model and divide by rmse. Multiply that by
% # 1 / sqrt(reliability of each survey), which is .y in the loop.
% .x$adj_pvnum <- resid(mod1)/rmse(mod1, .x) * 1 / sqrt(.y)

Where \begin{math}\hat{\epsilon_i}\end{math} is the residual for student \begin{math}i\end{math} and the denominator is the root mean square error of the model.

This new standardized variable has a mean of zero. Standardizing the median test score solves the problem of comparability of gaps measured with different tests, and across waves. However, if the variance of academic achievement changes over time, then standardizing the overall score at each country-wave pair actually makes the variable more biased. That is, by standardizing we're forcing the standard deviation of test scores to be zero across all waves. But if the true deviations of the median academic achievement changes over time, then the estimated trend in the SES gaps will be underestimated, or vice versa.

% Show graph of variance over time
% I'm showing standard deviations, is it better to show variance?
<<variance_pisa, cache = TRUE, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=

var_years <-
  map(adapted_year_data, function(.x) {
  .x %>%
  transmute(avg_cogn = matrixStats::rowMedians(as.matrix(select(.x, matches("^PV*.MATH$"))))) %>%
  summarize(var = sd(avg_cogn, na.rm = T),
            var_of_var = ) %>%
  pull(var)
})

enframer <- function(df, col_name = "name") {
  df %>%
    enframe(name = col_name) %>%
    unnest()
}

var_years %>%
  setNames(seq(2000, 2015, 3)) %>%
  enframer(name) %>%
  ggplot(aes(name, value)) + geom_col()
@

Inspection of the data suggests that it's something we shouldn't be deeply concerned with. The standard deviation of each wave seems to be following a very similar pattern with a not so drastic exception of the year 2000.

Another concern is that if the gaps at different waves are measured with tests that have different amounts of measurement error, then the amount of bias will not be the same in each measure of the gap. This can be very misleading and suggest erroneous intepretations regarding trends in the of the gaps over time \citep{reardon2011}. PISA has tried to make sure the tests are comparable across waves (PISA 2012 technical report), but we still have to adjust for this imprecision.

In order to correct gap estimates for measurement error, I adjust student test scores by

\begin{equation}
\hat{Y_i} = \hat{Y_i} * \frac{1}{\sqrt{r}}
\end{equation}

where \begin{math}r\end{math} is the reliability score of the wave. \footnote{Other proceedures multiply each country by their own reliability measure for each year-subject pair \citep{anna2016_global}. Unfortunately, PISA 2000 did not provide any reliability measure separately for each country and PISA 2015 has to yet release their own. At the moment of writing this paper, they were unavailable. For this reason we implement the analysis following the original work of \citet{reardon2011}}. Each PISA survey provides a reliability indicator which we use accordingly. This yields estimates of the true gaps, and eliminates any bias in the trend that may arise from differential reliability of the tests.

After constructing the adjusted test score measurement, we estimate the SES dummy by calculating the weighted 90th and 10th quantiles for the SES composite index, and then generating a dummy of 1 for those above (including) the 90th percentile and 0 for those below (including) the 10th percentile.

We then fit

\begin{equation}
Y_i = \alpha_{j[i]} + \beta_{j[i]} * SES_i + \epsilon_i,\ \text{for} \ i \ \text{= 1, 2, ...,} \ n \ \text{within country} \ j
\end{equation}

% mod2 <-
%   lmer(adj_pvnum ~ escs_dummy + (1 + escs_dummy | country),
%        data = .x,
%        weights = .x[[weights_var]])

where \(SES_i\) is whether the student is in the top/bottom SES dummy and we allow both \(\alpha_i\) and \(\beta_i\) to vary by country \(j\). We implement this separately for each wave and weight by the wave-specific student sample weights.

Finally, we calculate the SES achievement gap for each country by extracting the fitted \(\alpha\) and \(\beta\) for each country \(j\) and calculating the difference of the predicted score of High and Low SES.

\begin{equation}
\begin{split}
\quad \text{High SES}_j = \alpha_j + \beta_j \\
\quad \text{Low SES}_j = \alpha_j \\
\quad \text{SES gap}_j = \text{High SES}_j - \text{Low SES}_j
\end{split}
\end{equation}

We also calculate the standard error of this difference and use it to create uncertainty intervals in the estimation of time trends. We fit a multilevel rather than a linear model because by pooling the information together, we weight countries appropriately to their sample size. Given that including the SES dummy reduces the sample size considerably, we want to be able to estimate each country-difference as accurately as possible. For further exploration, we also compute the 90th/50th and 50th/10th SES gaps following the same method outlined above.

\section{Analysis}

\subsection{Descriptives}

% Show the properties of the ESCS dummy variable
% % in high educated
% % of home possessions
% % of ISEI

<<escsdummy_charachteristics, cache = TRUE, eval = F>>=
.x <- adapted_year_data[[1]]
country <- filter(.x, country == "United States")
probs <- c(0.1, 0.9)

escs_dummy_creator <- function(df, probs) {
  
    map(df, function(.x) {
      
      conf <- if (unique(.x$wave) == "pisa2015") pisa2015_conf else pisa_conf
      weights_var <- conf$variables$weightFinal

      country_split <- split(.x, .x$country)
      
      country_list <- map(country_split, function(country) {
        print(unique(country$country))
        
        quan <- quantile_missing(country, weights_var, probs)
        
        # It's very important to create a variable that returns the number of observations of this dummy
        # For each country. Possibly to weight by the number of observations.
        country$escs_dummy <-
          with(country, case_when(escs_trend >= quan[2] ~ 1,
                                  escs_trend <= quan[1] ~ 0))
        country
      })
      
      .x <-
        enframe(country_list) %>%
        unnest(value)
      
      message(paste(unique(.x$wave), "data ready"))
      
      .x
    })
}

escs_data <- escs_dummy_creator(adapted_year_data, c(0.1, 0.9))

# Make recode the education variable into three categories
map_lgl(escs_data, ~ "HISEI" %in% names(.x))

escs_data[[1]] %>%
  select(country, escs_dummy, high_edu_broad, ISEI) %>%
  filter(country %in% countries) %>%
  count(country, escs_dummy, high_edu_broad) %>%
  group_by(country, escs_dummy) %>%
  mutate(total_n = sum(n),
         perc = n / total_n * 100) %>%
  select(country, escs_dummy, high_edu_broad, perc) %>%
  map_if(is_double, round, 2) %>%
  as_tibble() %>%
  filter(!is.na(escs_dummy)) %>%
  spread(high_edu_broad, perc)

escs_data[[1]] %>%
  select(country, escs_dummy, high_edu_broad, ISEI) %>%
  filter(country %in% countries) %>%
  count(country, escs_dummy, isei_group = cut_number(ISEI, 4)) %>%
  group_by(country, isei_group) %>%
  mutate(total_n = sum(n),
         perc = n / total_n * 100) %>%
  select(country, escs_dummy, isei_group, perc) %>%
  map_if(is_double, round, 2) %>%
  as_tibble() %>%
  filter(!is.na(escs_dummy)) %>%
  spread(isei_group, perc) %>%
  left_join(m, by = c("country", "escs_dummy"))

@

% Figure out how to ouput data frames as latex tables.
<<sample_size, cache = TRUE>>=
# Get sample counts for each dummy
sample_size_calc <- function(df, probs, selected = F, cnts = NULL) {
  
  stopifnot(selected & !is.null(cnts))
  
  if (selected) df <- map(df, ~ filter(.x, country %in% cnts))
  
  cnt_to_bind <-
    map(df, function(df) {
      
      print(unique(df$wave))
      conf <- if (unique(df$wave) == "pisa2015") pisa2015_conf else pisa_conf
      weights_var <- conf$variables$weightFinal
      
      split_df <- split(df, df$country)
      
      split_df_two <-
        map(split_df, ~ {
          # In some countries the quan can't be estimated because of very few obs.
          # The function doesn't stop but returns two NA's.
          quan <- quantile_missing(.x, weights_var, probs)
          
          # It's very important to create a variable that returns the number of observations of this dummy
          # For each country. Possibly to weight by the number of observations.
          .x$escs_dummy <-
            with(.x, case_when(escs_trend >= quan[2] ~ 1,
                               escs_trend <= quan[1] ~ 0))
          .x
        })
      unsplit_df <- split_df_two %>% enframe() %>% unnest(value)
      
      unsplit_df %>%
        count(country, escs_dummy) %>%
        filter(!is.na(escs_dummy)) %>%
        left_join(summarize(group_by(unsplit_df, country), total_n = n()), by = "country") %>%
        mutate(perc = paste0(round(n / total_n * 100, 0), "%")) %>%
        select(-total_n)
    })
  setNames(cnt_to_bind, seq(2000, 2015, 3)) %>%
    enframe() %>%
    unnest()
}

sample_tables_topbottom <- sample_size_calc(adapted_year_data, c(.1, .9), selected = TRUE, countries)
sample_tables_topmid <- sample_size_calc(adapted_year_data, c(.5, .9), selected = TRUE, countries)
sample_tables_midbottom <- sample_size_calc(adapted_year_data, c(.1, .5), selected = TRUE, countries)
@

<<merge_math_read, cache = TRUE>>=

# Function does a lot of things, but in short:

# Calculate the difference between the gap and together with it's joint s.e
# Also uncertainty intervals and returns a tibble with the difference between
# SES gaps with the adjusted SE difference + uncertainty intervals + the original
# data (the absolute numbers before the differences)

pisa_preparer <- function(df_math, df_read) {

descrip_math <- map(df_math, ~ rename(.x, mean_math = Mean, se_math = s.e.))
descrip_read <- map(df_read, ~ rename(.x, mean_read = Mean, se_read = s.e.))


reduced_data_math <-
  map2(descrip_math, years, function(.x, .y) {
    .x %>%
      mutate(wave = .y) %>%
      filter(!is.na(escs_dummy))
  }) %>%
  bind_rows() %>%
  as_tibble() %>%
  mutate(lower_math = mean_math - 1.96 * se_math,
         upper_math = mean_math + 1.96 * se_math)

reduced_data_read <-
  map2(descrip_read, years, function(.x, .y) {
    .x %>%
      mutate(wave = .y) %>%
      filter(!is.na(escs_dummy))
  }) %>%
  bind_rows() %>%
  as_tibble() %>%
  mutate(lower_read = mean_read - 1.96 * se_read,
         upper_read = mean_read + 1.96 * se_read)

reduced_data <- left_join(reduced_data_math,
                          reduced_data_read, by = c("country", "escs_dummy", "wave"))

# Merging math and reading data
test_data <-
  reduced_data %>%
  select(country, wave, escs_dummy, contains("mean")) %>%
  gather(test, score, contains("mean"))

math_data <-
  reduced_data %>%
  select(country, wave, escs_dummy, contains("math")) %>%
  gather(test_bound, bound, contains("lower"), contains("upper")) %>%
  select(-contains("math")) %>%
  right_join(filter(test_data, test == "mean_math"))

read_data <-
  reduced_data %>%
  select(country, wave, escs_dummy, contains("read")) %>%
  gather(test_bound, bound, contains("lower"), contains("upper")) %>%
  select(-contains("read")) %>%
  right_join(filter(test_data, test == "mean_read"))

all_data <- bind_rows(math_data, read_data)

# Calculate the joint standard error of the difference
math_se_data <-
  reduced_data %>%
  select(country, escs_dummy, wave, se_math) %>%
  spread(escs_dummy, se_math) %>%
    transmute(country, wave,
              se_diff_math = sqrt(abs(`1`^2 - `0`^2)))

read_se_data <-
  reduced_data %>%
  select(country, escs_dummy, wave, se_read) %>%
  spread(escs_dummy, se_read) %>%
  transmute(country, wave,
            se_diff_read = sqrt(abs(`1`^2 - `0`^2)))

se_data <- left_join(math_se_data, read_se_data)

# Calculate the different between the gap and together with it's joint s.e graph
# the absolut difference.

math_diff <-
  reduced_data %>%
  select(wave, country, escs_dummy, mean_math) %>%
  spread(escs_dummy, mean_math) %>%
  transmute(wave, country, diff_math = `1` - `0`)

read_diff <-
  reduced_data %>%
  select(wave, country, escs_dummy, mean_read) %>%
  spread(escs_dummy, mean_read) %>%
  transmute(wave, country, diff_read = `1` - `0`)

data_summaries <-
  math_diff %>%
  left_join(read_diff) %>%
  left_join(se_data) %>%
  transmute(wave, country, diff_math, diff_read,
           lower_math = diff_math - 1.96 * se_diff_math,
           lower_read = diff_read - 1.96 * se_diff_read,
           upper_math = diff_math + 1.96 * se_diff_math,
           upper_read = diff_read + 1.96 * se_diff_read)

differences <-
  data_summaries %>%
  select(wave, country, diff_math, diff_read) %>%
  gather(test, difference, starts_with("diff")) %>%
  mutate(type_test = ifelse(.$test == "diff_math", "math", "read"))

bounds_lower <-
  data_summaries %>%
  select(wave, country, contains("lower")) %>%
  gather(lower_bound, lower, lower_math, lower_read) %>%
  mutate(type_test = ifelse(grepl("math", .$lower_bound), "math", "read"))

bounds_upper <-
  data_summaries %>%
  select(wave, country, contains("upper")) %>%
  gather(upper_bound, upper, upper_math, upper_read) %>%
  mutate(type_test = ifelse(grepl("math", .$upper_bound), "math", "read"))

# Getting the original data in
original_math <-
  reduced_data_math %>%
  select(wave, everything(), -se_math) %>%
  gather(metric, value, -(wave:escs_dummy)) %>%
  unite(combination, escs_dummy, metric, sep = "_") %>%
  spread(combination, value) %>%
  mutate(type_test = "math")

original_read <-
  reduced_data_read %>%
  select(wave, everything(), -se_read) %>%
  gather(metric, value, -(wave:escs_dummy)) %>%
  unite(combination, escs_dummy, metric, sep = "_") %>%
  spread(combination, value) %>%
  mutate(type_test = "read")

# final data
complete_data <-
  left_join(differences, bounds_lower) %>%
  left_join(bounds_upper) %>%
  left_join(original_math) %>%
  left_join(original_read)
}

complete_data_topbottom <- pisa_preparer(results_math, results_read)
complete_data_topmid <- pisa_preparer(results_math_topmid, results_read_topmid)
complete_data_midbottom <- pisa_preparer(results_math_midbottom, results_read_midbottom)

complete_data_topbottom <- mutate(complete_data_topbottom, type = "90th/10th SES gap")
complete_data_topmid <- mutate(complete_data_topmid, type = "90th/50th SES gap")
complete_data_midbottom <- mutate(complete_data_midbottom, type = "50th/10th SES gap")
@

<<correlation_incomeineq, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
complete_data_topbottom %>%
  mutate(wave = as.character(wave)) %>%
  left_join(inequalityintsvy::economic_inequality, by = c("wave" = "year", "country")) %>%
  filter(indicators == "GINI") %>%
  group_by(country) %>%
  summarize(avg_diff = mean(difference, na.rm = T),
            avg_value = mean(value, na.rm = T)) %>%
  filter(avg_value < 8) %>%
  ggplot(aes(avg_value, avg_diff)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ splines::ns(x, 2), linetype = "longdash", se = F)
@

\subsection{Results}

Calculate the difference between 90/10 and then the ratio of this with the annual gain of one year of schooling (\citet{micklewright} did it).

<<graphing_9010gaps, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
# 90/10 gaps acros countries
diff_increase_fun <- function(df) {
  
  # Average standard deviation increase
  data_ready <-
    df %>%
    select(wave, country, type_test, difference) %>%
    group_by(type_test) %>%
    split(.$country) %>%
    map(~ {
      .x <-
        spread(.x, wave, difference) %>%
        ungroup()
  
      year_vars <- sum(map_dbl(.x, is.numeric)) - 1
      years_subtract <- names(.x)[c(ncol(.x) - year_vars, ncol(.x))]
      years_subtract <- lapply(years_subtract, as.name)

      last_year <- rlang::new_quosure(years_subtract[[2]], env = .GlobalEnv)
      first_year <- rlang::new_quosure(years_subtract[[1]], env = .GlobalEnv)
      
      years_available <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        group_by(type_test) %>%
        summarise(yr_avaible = sum(!is.na(val))) %>%
        pull(yr_avaible)
      
      year_sd <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        split(.$type_test) %>%
        map_dbl(~ bootstrapper(.x, mad(val, na.rm = T), B = 100) %>% .[[2, 2]]) %>%
        round(2) * 100

      
      .x %>%
        map_if(is_double, round, 3) %>%
        as_tibble() %>%
        transmute(type_test,
                  country,
                  diff = round(((!!last_year) - (!!first_year)), 1),
                  sd_year = year_sd,
                  diff_lower = diff - 1 * year_sd,
                  diff_upper = diff + 1 * year_sd,
                  years_available = years_available)
    })
  data_ready
}

diff_data <-
  diff_increase_fun(complete_data_topbottom) %>%
  enframer("country") %>%
  filter(country %in% countries) %>%
  select(country, type_test, diff) %>%
  split(.$type_test) %>%
  map(~ .x %>% select(-type_test) %>% deframe())

lm_data <- function(df) {
  lm(log(difference) ~ wave, data = df) %>%
    broom::tidy() %>%
    mutate(estimate = exp(estimate))
}

ordered_cnt <-
  complete_data_topbottom %>%
  filter(type_test == "math") %>%
  select(wave, country, difference) %>%
  filter(country %in% countries) %>%
  split(.$country) %>%
  map(lm_data) %>%
  enframer("country") %>%
  filter(term == "wave") %>%
  arrange(-estimate) %>%
  pull(country)

complete_data_topbottom %>%
  filter(country %in% countries) %>%
  mutate(country = factor(country, levels = ordered_cnt, ordered = TRUE)) %>%
  ggplot(aes(as.factor(wave), difference, group = type_test, colour = type_test)) +
  geom_line(stat = "smooth", method = "lm", aes(group = 1),
            formula = y ~ splines::ns(x, 3), linetype = "longdash",
            colour = "black") +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1, alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "longdash") +
  geom_line(alpha = 0.4) +
  geom_point(size = 0.5, alpha = 0.4) +
  coord_cartesian(ylim = c(0, 3)) +
  facet_wrap(~ country)
@

We start by look at the achievement for some countries. We plot both mathematics and reading gaps for each country and also a cubic trend spline for both test scores pooled. Some countries have increased their achievement very strongly. For example, France, Austria and surprisingly Sweden. In mathematics, France increase the gap by roughly \Sexpr{diff_data$math[["France"]]}. This increase happens similarly for literacy with an increase of \Sexpr{diff_data$read[["France"]]}. For such a short period of time, the magnitud of the increase is reasonably big.

Given that no one has estimated the evolution of the gap we can't cross-check how other empirical estimations put France. However, we can make some educated inferences.  For example, \citet{micklewright} also finds that France is a low dispersion country, specifically in the year 2000. They also find that Germany and US are very dispersed countries (quite the opposite).

\citet{micklewright} find that France has a very small gap in 2000, something we find very clearly in our data, and the U.S has a very big gap in 2000, something we also find in our data. \citet{micklewright} find
that average achievement is negatively related to dispersion.

It seems that social origin effects have actually increased in France  (Ballarino and Bernardi, 2016)


<<graphing_allgaps, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=

# Comparing all gaps across countries
complete_data_topbottom %>%
  bind_rows(complete_data_topmid) %>%
  bind_rows(complete_data_midbottom) %>%
  filter(country %in% c("United States", "Denmark", "France")) %>%
  mutate(type = factor(type,
                       levels = c("90th/10th SES gap", "90th/50th SES gap", "50th/10th SES gap"),
                       ordered = TRUE)) %>%
  ggplot(aes(as.factor(wave), difference, group = type_test, colour = type_test)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) +
  geom_hline(yintercept = 0, linetype = "longdash") +
  geom_line() +
  geom_point(size = 0.5) +
  coord_cartesian(ylim = c(-0.5, 3)) +
  facet_grid(country ~ type)
@

<<graphing_ses_growth, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
# Graphing how the top/bottom are evolving over time instead of absolute difference

complete_data_topbottom %>%
  bind_rows(complete_data_topmid) %>%
  bind_rows(complete_data_midbottom) %>%
  filter(country %in% c("Germany", "Denmark", "France"), type_test == "math") %>%
  select(wave, country, type_test, type, contains("math")) %>%
  mutate(type = factor(type,
                       levels = c("90th/10th SES gap", "90th/50th SES gap", "50th/10th SES gap"),
                       ordered = TRUE)) %>%
  gather(score, value, -(wave:type)) %>%
  separate(score, c("ses", "score"), sep = 2) %>%
  spread(score, value) %>%
  ggplot(aes(as.factor(wave), mean_math, group = ses, colour = ses)) +
  geom_errorbar(aes(ymin = lower_math, ymax = upper_math), width = 0.1) +
  geom_hline(yintercept = 0, linetype = "longdash") +
  geom_line() +
  geom_point(size = 0.5) +
  coord_cartesian(ylim = c(-0.5, 3)) +
  facet_grid(country ~ type)

# Increase:  
# Sweden - steady increase in both tests
# Austria - increase in math - slight increase in read
# Finland - very sharp increase in both
# France - very sharp increase in both
# Netherlands - sharp increase in both

# Decrease:
# US - decrease in both tests
# Chile - decrease in both tests
  
# No change:
# Canada - stable red - increase math
# UK - slight decrease red - stable math
# Belgium - no change
# Czech republic - no change
# Denmark no change
# Germany - no change
# ITaly - no change
# Japan -  no change
# Norway - no change
# Poland - no change
# Spain - no change
@

<<graphing_achievement_disparity, cache = T>>=

country_scores <-
  map(adapted_year_data, ~ {
  if (unique(.x$wave) == "pisa2015") {
    intsvy::pisa2015.mean.pv("MATH", by = "country", data = .x)
  } else {
    intsvy::pisa.mean.pv("MATH", by = "country", data = .x)
  }
}) %>% setNames(seq(2000, 2015, 3))

country_scores <-
  enframe(country_scores, name = "wave") %>%
  unnest() %>%
  mutate(wave = as.double(wave))

data_to_plot <-
  left_join(complete_data_topbottom, country_scores, by = c("wave", "country")) %>%
  select(wave, country, type_test, difference, Mean) %>%
  filter(type_test == "math")

data_to_plot %>%
  ggplot(aes(scale(Mean), difference)) +
  geom_point() +
  geom_smooth()

data_to_plot %>%
  filter(country %in% countries) %>%
  ggplot(aes(as.character(wave), difference, group = country)) +
  geom_point(colour = "blue") +
  geom_line(colour = "blue") +
  geom_point(aes(y = scale(Mean)), colour = "red") +
  geom_line(aes(y = scale(Mean)), colour = "red") +
  facet_wrap(~ country)

data_to_plot %>%
  semi_join(data_to_plot %>% group_by(country) %>% count() %>% filter(n > 3), by = "country") %>%
  group_by(country) %>%
  summarize(cor = cor(scale(Mean), difference, use = 'complete.obs')) %>%
  ggplot(aes(reorder(country, cor), cor, fill = cor > 0)) + geom_col() + coord_flip()

@

% How to output data frames are latex tables?
<<rate_change, cache = TRUE>>=

avg_increase_fun <- function(df, class) {

# Average standard deviation increase
  data_ready <-
    df %>%
    select(wave, country, type_test, contains("mean_math")) %>%
    gather(metric, value, -(wave:type_test)) %>%
    separate(metric, c("ses", "test"), sep = 2) %>%
    spread(test, value) %>%
    mutate(ses = gsub("_", "", ses)) %>%
    filter(type_test == "math", ses == class) %>%
    split(.$country) %>%
    map(~ mutate(.,
                 diff = c(diff(mean_math, lag = 1), NA),
                 perc = round(diff / mean_math, 2) * 100,
                 perc_pos = mean(perc > 0, na.rm = T))) %>%
    enframe() %>%
    unnest(value) %>%
    split(.$country)
  
    map2(data_ready, names(data_ready), ~ {

      print(.y)
      
      mean_df <-
        bootstrapper(.x, mean(diff, na.rm = T), B = 500) %>%
        filter(type == "bootstrap") %>%
        rename(mean = value)

      sd_df <-
        bootstrapper(.x, sd(diff, na.rm = T), B = 500) %>%
        filter(type == "bootstrap") %>%
        rename(sd = value)
      
      suppressMessages(
        left_join(mean_df, sd_df) %>%
        mutate(lower_bound = mean - 1 * sd,
               upper_bound = mean + 1 * sd)
      )
    }) %>%
    enframe() %>%
    unnest(value)
}

avg_sd_increase_high <- avg_increase_fun(complete_data_topbottom, 1)
avg_sd_increase_low <- avg_increase_fun(complete_data_topbottom, 0)
@

<<rate_change_graph, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=

full_data <-
  left_join(select(avg_sd_increase_high, name, mean),
            select(avg_sd_increase_low, name, mean), by = "name") %>%
  mutate(continent = ifelse(name %in% countries, "my_cnt", "other_cnt"))

colnames(full_data) <- c("country", "high_increase", "low_increase", "continent")

lims <- list(xlim = c(-0.15, 0.25), ylim = c(-0.25, 0.25))

rect_data <- tibble(xst = c(lims$xlim[1], 0),
                    xen = c(0.0, lims$xlim[2]),
                    yst = c(0.0, lims$ylim[1]),
                    yen = c(lims$ylim[2], 0),
                    colour = c("red", "green"))

full_data %>%
  ggplot(aes(low_increase, high_increase), alpha = 0.2) +
  geom_rect(data = rect_data, aes(xmin = xst,
                                  xmax = xen,
                                  ymin = yst,
                                  ymax = yen),
            fill = rect_data$colour,
            alpha = 0.2,
            inherit.aes = FALSE) +
  geom_line(stat="smooth", method = "lm", se = FALSE, alpha = 0.5, colour = "grey", size = 1) +
  geom_point(alpha = 0.2) +
  geom_point(data = filter(full_data, continent == "my_cnt"), colour = "red", alpha = 0.7) +
  geom_text_repel(data = filter(full_data, continent == "my_cnt"),
                  aes(label = country), box.padding = unit(2.7, "lines")) +
  geom_vline(xintercept = 0, alpha = 0.5) +
  geom_hline(yintercept = 0, alpha = 0.5) +
  xlim(lims$xlim) +
  ylim(lims$ylim) +
  coord_cartesian(expand = FALSE) +
  annotate(geom = "text", x = 0.15, y = -0.2,
           label = "Low SES are catching up \n faster than High SES",
           fontface = 2, size = 3) +
  annotate(geom = "text", x = -0.05, y = 0.20,
           label = "High SES are increasing  \n faster than Low SES",
           fontface = 2, size = 3) +
  labs(x = "Average increase of low SES in SD", y = "Average increase of high SES in SD") +
  theme_minimal()
@

% How to output data frames are latex tables?
<<perc_increase_tables, cache = TRUE>>=
# Show the rates at which is increasing/decreasing
perc_increase_fun <- function(df) {
  
  # Average standard deviation increase
  data_ready <-
    df %>%
    select(wave, country, type_test, difference) %>%
    group_by(type_test) %>%
    split(.$country) %>%
    map(~ {
      .x <-
        spread(.x, wave, difference) %>%
        ungroup()
  
      year_vars <- sum(map_dbl(.x, is.numeric)) - 1
      years_subtract <- names(.x)[c(ncol(.x) - year_vars, ncol(.x))]
      years_subtract <- lapply(years_subtract, as.name)

      last_year <- rlang::new_quosure(years_subtract[[2]], env = .GlobalEnv)
      first_year <- rlang::new_quosure(years_subtract[[1]], env = .GlobalEnv)
      
      years_available <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        group_by(type_test) %>%
        summarise(yr_avaible = sum(!is.na(val))) %>%
        pull(yr_avaible)
      
      year_sd <-
        .x %>%
        gather(year, val, -(country:type_test)) %>%
        split(.$type_test) %>%
        map_dbl(~ bootstrapper(.x, mad(val, na.rm = T), B = 100) %>% .[[2, 2]]) %>%
        round(2) * 100

      
      .x %>%
        map_if(is_double, round, 3) %>%
        as_tibble() %>%
        transmute(type_test,
                  country,
                  perc_diff = round(((!!last_year) - (!!first_year)) * 100, 1),
                  sd_year = year_sd,
                  diff_lower = perc_diff - 1 * year_sd,
                  diff_upper = perc_diff + 1 * year_sd,
                  years_available = years_available)
    })
  data_ready
}

top_bottom_perc <- perc_increase_fun(complete_data_topbottom)
top_mid_perc <- perc_increase_fun(complete_data_topmid)
mid_bottom_perc <- perc_increase_fun(complete_data_midbottom)

# Gap is closing at an average of the variable diff per year.
@

<<graphing_perc_increase, include = T, out.height = '5in', out.width = '5.5in', fig.align = 'center'>>=
perc_graph <- function(df) {
  df %>%
  enframe(name = "country") %>%
  unnest(value) %>%
  filter(country %in% countries) %>%
  select(-country1, -years_available) %>%
  mutate(diff_95_lower = perc_diff - 2*sd_year,
         diff_95_upper = perc_diff + 2*sd_year) %>%
  setNames(c("Country", "Type of test", "Average % difference", "Average SD",
             "Lower 50% bound", "Upper 50% bound", "Lower 95% bound", "Upper 95% bound")) %>%
  filter(`Type of test` == "math") %>%
  arrange(`Average % difference`) %>%
  mutate(Country = ordered(forcats::as_factor(Country)),
         Country_num = as.numeric(Country)) %>%
  ggplot(aes(Country, `Average % difference`)) +
  geom_point() +
  geom_ribbon(aes(x = Country_num, ymin = `Lower 95% bound`, ymax = `Upper 95% bound`), alpha = 0.5) +
  geom_ribbon(aes(x = Country_num, ymin = `Lower 50% bound`, ymax = `Upper 50% bound`), alpha = 0.5) +
  geom_hline(yintercept = 0, linetype = "longdash") +
  scale_y_continuous(breaks = seq(-160, 160, 40)) +
  coord_cartesian(ylim = c(-160, 160)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

m1 <- perc_graph(top_bottom_perc)
m2 <- perc_graph(top_mid_perc)
m3 <- perc_graph(mid_bottom_perc)

gridExtra::grid.arrange(m1, m2, m3, nrow = 1)
@

<<table_sample>>=
sample_tables_topbottom %>%
  filter(name %in% c(2000, 2015)) %>%
  transmute(name, country, escs_dummy, N = paste0(n, " (", perc, ")")) %>%
  spread(escs_dummy, N) %>%
  rename(Year = name,
         Country = country,
         `10th SES` = `0`,
         `90th SES` = `1`) %>%
  select(Country, Year, everything()) %>%
  arrange(Country, Year) %>%
  xtable::xtable()
@

<<next_steps>>=
# Next steps:

# Continue by doing the multilevel models to see what explains what. Include
# all indicators from the reardon/russian girl paper.
  
# Graph the increase in each country vs the increase/decrease of the economic inequality indicators
# Specially the 90/10

# Calculate how big is the gap between reading and math
  
# Continue with the PIRLS to see if there are specific patterns in 4th and 8th graders gap.
  
# Get each country trendline adjusted for the inequality indicators and place in the same country graph.

# Should I add the parent's education in the lm model to see how trends change adjusted for that?

# A weak welfare system, together with income inequality, what's their pattern?
# What if we put the school differentiation/tracking aspect in? Are there country groups based on these
# patterns.

# In countries where there is high differentiation/tracking, is there a jump in the evolution of the gap between PIRLS/TIMSS and PISA?
@

\bibliography{mybibliography.bib}

\end{document}
